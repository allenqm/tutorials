{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Training a Classifier\n",
    "=====================\n",
    "\n",
    "This is it. You have seen how to define neural networks, compute loss and make\n",
    "updates to the weights of the network.\n",
    "\n",
    "Now you might be thinking,\n",
    "\n",
    "What about data?\n",
    "----------------\n",
    "\n",
    "Generally, when you have to deal with image, text, audio or video data,\n",
    "you can use standard python packages that load data into a numpy array.\n",
    "Then you can convert this array into a ``torch.*Tensor``.\n",
    "\n",
    "-  For images, packages such as Pillow, OpenCV are useful\n",
    "-  For audio, packages such as scipy and librosa\n",
    "-  For text, either raw Python or Cython based loading, or NLTK and\n",
    "   SpaCy are useful\n",
    "\n",
    "Specifically for vision, we have created a package called\n",
    "``torchvision``, that has data loaders for common datasets such as\n",
    "Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
    "``torchvision.datasets`` and ``torch.utils.data.DataLoader``.\n",
    "\n",
    "This provides a huge convenience and avoids writing boilerplate code.\n",
    "\n",
    "For this tutorial, we will use the CIFAR10 dataset.\n",
    "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
    "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of\n",
    "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
    "\n",
    ".. figure:: /_static/img/cifar10.png\n",
    "   :alt: cifar10\n",
    "\n",
    "   cifar10\n",
    "\n",
    "\n",
    "Training an image classifier\n",
    "----------------------------\n",
    "\n",
    "We will do the following steps in order:\n",
    "\n",
    "1. Load and normalizing the CIFAR10 training and test datasets using\n",
    "   ``torchvision``\n",
    "2. Define a Convolutional Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data\n",
    "\n",
    "1. Loading and normalizing CIFAR10\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "Using ``torchvision``, it’s extremely easy to load CIFAR10.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "We transform them to Tensors of normalized range [-1, 1].\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>If running on Windows and you get a BrokenPipeError, try setting\n",
    "    the num_worker of torch.utils.data.DataLoader() to 0.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10('~/storage', train=True, download=False, transform=transform) #downloading does not work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.CIFAR10('~/storage', train=False, download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us show some of the training images, for fun.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  car   dog   dog  deer\n"
     ]
    }
   ],
   "source": [
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 32, 32])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define a Convolutional Neural Network\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "Copy the neural network from the Neural Networks section before and modify it to\n",
    "take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net1 = Net1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1)),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)),\n",
       " Linear(in_features=400, out_features=120, bias=True),\n",
       " Linear(in_features=120, out_features=84, bias=True),\n",
       " Linear(in_features=84, out_features=10, bias=True)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(size=(4, 3, 32, 32))\n",
    "y = torch.tensor(x.numpy())\n",
    "(x == y).sum() == torch.ones_like(x, dtype=torch.int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net1 = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "#x = torch.rand(size=(4, 3, 32, 32))\n",
    "print(x.shape)\n",
    "x = F.relu(net.conv1(x))\n",
    "# print(x.shape)\n",
    "# x = net.pool(x)\n",
    "# print(x.shape)\n",
    "# x = F.relu(net.conv2(x))\n",
    "# print(x.shape)\n",
    "# x = x.view(-1, 16*5*5)\n",
    "# print(x.shape)\n",
    "# x = F.relu(net.fc1(x))\n",
    "# print(x.shape)\n",
    "# x = F.relu(net.fc2(x))\n",
    "# print(x.shape)\n",
    "# x = net.fc3(x)\n",
    "# print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "y = F.relu(net1.conv1(y))\n",
    "# print(y.shape)\n",
    "# y = net1.pool(y)\n",
    "# print(y.shape)\n",
    "# y = F.relu(net1.conv2(y))\n",
    "# print(y.shape)\n",
    "# y = y.view(-1, 16*5*5)\n",
    "# print(y.shape)\n",
    "# y = F.relu(net1.fc1(y))\n",
    "# print(y.shape)\n",
    "# y = F.relu(net1.fc2(y))\n",
    "# print(y.shape)\n",
    "# y = net1.fc3(y)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x == y).sum() == torch.ones_like(x, dtype=torch.int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(model_1, model_2):\n",
    "    models_differ = 0\n",
    "    for key_item_1, key_item_2 in zip(model_1.state_dict().items(), model_2.state_dict().items()):\n",
    "        if torch.equal(key_item_1[1], key_item_2[1]):\n",
    "            pass\n",
    "        else:\n",
    "            models_differ += 1\n",
    "            if (key_item_1[0] == key_item_2[0]):\n",
    "                print('Mismtach found at', key_item_1[0])\n",
    "            else:\n",
    "                raise Exception\n",
    "    if models_differ == 0:\n",
    "        print('Models match perfectly! :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismtach found at conv1.weight\n",
      "Mismtach found at conv1.bias\n",
      "Mismtach found at conv2.weight\n",
      "Mismtach found at conv2.bias\n",
      "Mismtach found at fc1.weight\n",
      "Mismtach found at fc1.bias\n",
      "Mismtach found at fc2.weight\n",
      "Mismtach found at fc2.bias\n",
      "Mismtach found at fc3.weight\n",
      "Mismtach found at fc3.bias\n"
     ]
    }
   ],
   "source": [
    "compare_models(net, net1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 9.7011e-02, -7.0986e-02, -5.0680e-02,  2.1627e-02, -4.0288e-02],\n",
       "          [ 8.1597e-02, -1.7908e-02, -9.3028e-02,  1.2518e-03, -9.1645e-02],\n",
       "          [ 2.3220e-02,  2.4334e-02, -7.0428e-02,  1.3461e-02,  1.2526e-02],\n",
       "          [-1.0423e-01, -1.6604e-02, -9.5009e-02, -5.6317e-02, -1.1458e-01],\n",
       "          [-7.3696e-02,  9.2810e-02, -6.7467e-02, -4.3678e-02, -6.4489e-03]],\n",
       "\n",
       "         [[-7.7403e-02,  4.7599e-02, -6.7939e-02, -6.1037e-02, -3.6515e-02],\n",
       "          [-5.2274e-02, -3.8494e-02,  1.1365e-01, -2.4925e-02, -8.1308e-02],\n",
       "          [-1.0075e-01,  1.0823e-01,  2.3625e-02,  7.6865e-02, -1.9780e-02],\n",
       "          [ 9.2719e-03,  3.2250e-02,  7.6738e-02, -1.1412e-01, -1.0044e-01],\n",
       "          [ 7.1153e-02, -1.0216e-01, -5.4211e-02,  7.8163e-02, -4.6775e-02]],\n",
       "\n",
       "         [[ 3.1148e-02, -1.1238e-01,  4.9241e-02, -6.2325e-02, -1.0559e-01],\n",
       "          [ 1.1105e-01,  2.1416e-02, -9.6451e-02, -6.6975e-02, -9.0657e-02],\n",
       "          [-5.7376e-02, -3.5508e-02,  1.6550e-02,  8.6849e-02,  9.5923e-02],\n",
       "          [ 7.4250e-02,  6.3212e-02, -9.2907e-02, -1.6288e-02, -7.4885e-02],\n",
       "          [-1.1261e-01,  9.8263e-02, -8.1134e-02, -1.2369e-02,  8.1375e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.6945e-02, -7.5287e-02,  9.7908e-03,  8.6044e-02,  4.6488e-02],\n",
       "          [-2.4314e-02, -7.8554e-02,  3.9658e-02, -2.3563e-02, -9.7361e-02],\n",
       "          [ 8.3038e-02,  5.3385e-02, -1.4057e-03, -6.5836e-02, -1.0997e-01],\n",
       "          [-2.1078e-02,  1.3376e-02, -4.9314e-02,  3.3444e-02,  1.5432e-02],\n",
       "          [ 3.2493e-03,  9.5318e-02, -1.0649e-01, -1.1174e-01,  3.4765e-02]],\n",
       "\n",
       "         [[-9.0219e-02, -5.4670e-03,  3.0253e-02, -5.3186e-02, -7.5512e-02],\n",
       "          [ 1.0220e-01,  1.1328e-01, -8.4383e-02,  1.1212e-01, -5.9861e-03],\n",
       "          [-3.9465e-02, -4.5806e-02, -1.1519e-01,  6.7181e-02, -5.3756e-02],\n",
       "          [-1.4151e-02, -5.4554e-02,  8.7236e-02, -7.8946e-02,  2.0516e-02],\n",
       "          [ 9.3797e-02, -3.1939e-02, -5.9906e-02,  4.1803e-02, -7.5665e-02]],\n",
       "\n",
       "         [[ 7.9067e-02, -1.0829e-02,  3.6126e-02,  5.9646e-03, -2.2042e-02],\n",
       "          [-5.6970e-02, -6.7975e-02,  2.1599e-02, -5.5347e-02,  1.1393e-01],\n",
       "          [ 4.8053e-02, -1.1491e-01,  4.2681e-02,  1.0066e-01,  5.7225e-02],\n",
       "          [ 3.7228e-02, -1.0659e-01, -1.0784e-01,  5.7063e-02, -5.5052e-02],\n",
       "          [ 1.0735e-01,  3.6946e-03,  6.2661e-02, -5.4081e-02,  8.2190e-02]]],\n",
       "\n",
       "\n",
       "        [[[-6.3646e-02, -1.2171e-02,  5.1464e-02,  2.0812e-02, -5.3597e-02],\n",
       "          [-2.6933e-02,  8.9427e-02, -1.1733e-02, -8.6958e-02,  8.8319e-02],\n",
       "          [-3.8558e-02, -2.2938e-02,  1.0786e-01,  3.8217e-02, -9.1548e-02],\n",
       "          [ 9.5661e-02,  3.7048e-02, -8.3999e-02, -8.0329e-02, -7.6232e-02],\n",
       "          [ 8.4946e-02, -5.0368e-02,  4.5219e-02, -8.1882e-02,  2.1496e-02]],\n",
       "\n",
       "         [[ 6.5425e-02,  5.0028e-02,  4.7118e-02,  9.4167e-02, -8.8159e-02],\n",
       "          [-7.3232e-02, -3.0179e-02, -6.2756e-02, -9.8577e-02,  8.7076e-02],\n",
       "          [-7.1198e-02,  5.1464e-02,  2.9676e-02,  7.1935e-03, -7.6556e-02],\n",
       "          [ 9.4313e-02, -8.4722e-02,  6.9810e-02, -1.5858e-02, -7.4159e-02],\n",
       "          [-4.3951e-02, -5.2072e-02, -1.1368e-01,  5.5897e-02, -2.9524e-02]],\n",
       "\n",
       "         [[-3.6438e-02, -6.1535e-02, -1.0132e-01, -1.7232e-02, -6.9233e-02],\n",
       "          [-8.2176e-03, -1.1016e-01, -6.0802e-02, -7.3377e-03,  6.4098e-02],\n",
       "          [-1.6209e-02, -1.1228e-01, -7.7566e-02,  1.4592e-02, -2.5569e-02],\n",
       "          [-8.1549e-02, -1.0972e-01, -1.0775e-01,  4.7703e-02,  5.6897e-02],\n",
       "          [-1.4378e-02, -2.3681e-02, -2.2586e-02, -6.9355e-03, -1.0434e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 9.3762e-02, -1.1216e-01, -6.2957e-03,  5.3578e-02,  1.0666e-01],\n",
       "          [ 1.9817e-02, -4.1498e-02,  7.3873e-02, -3.9436e-02,  6.0440e-02],\n",
       "          [ 6.3668e-02,  3.8557e-02, -6.8636e-03, -7.0644e-02,  9.0610e-02],\n",
       "          [ 7.3761e-02, -6.9710e-02, -3.0957e-03, -1.0710e-01,  7.4123e-03],\n",
       "          [-9.9643e-02, -5.3618e-02,  9.1150e-02, -1.0864e-01, -2.8493e-02]],\n",
       "\n",
       "         [[-4.1852e-02,  1.0692e-02, -1.8428e-02, -8.5635e-02, -2.1865e-02],\n",
       "          [-2.3554e-02,  8.2217e-03,  1.8439e-02, -9.6486e-02, -1.7721e-02],\n",
       "          [ 3.3116e-02,  2.3474e-02,  7.9623e-02, -9.2075e-03, -7.0783e-02],\n",
       "          [-6.4343e-02, -8.1650e-02, -4.2554e-02,  1.4233e-02,  4.8295e-02],\n",
       "          [-1.5718e-02,  4.3258e-02,  3.7946e-03,  5.6153e-03, -1.1379e-01]],\n",
       "\n",
       "         [[ 1.0683e-01, -8.2759e-02, -8.0063e-02,  9.1073e-02, -3.0534e-02],\n",
       "          [ 1.5430e-02, -3.7413e-02,  3.7420e-02,  1.0474e-01, -6.3178e-02],\n",
       "          [ 3.0403e-02,  7.5641e-03,  6.3269e-03, -4.7828e-02,  6.7690e-02],\n",
       "          [-9.6000e-02, -3.4193e-02,  8.4696e-02, -7.6428e-02,  6.0516e-02],\n",
       "          [ 1.2024e-02, -8.6438e-02, -6.9373e-02,  1.0109e-01, -8.7238e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.6037e-02,  1.4900e-02,  3.3808e-02, -3.3674e-02, -5.5273e-02],\n",
       "          [-3.8632e-02,  4.4728e-02,  5.7744e-02,  6.7515e-02, -5.8823e-02],\n",
       "          [ 3.6914e-02,  4.8579e-02,  3.3652e-02, -9.3411e-02, -8.0249e-02],\n",
       "          [-4.3482e-02, -9.7915e-02, -1.6541e-02, -6.9479e-02, -4.2139e-02],\n",
       "          [ 2.2148e-02, -1.1390e-02,  6.9588e-02, -6.6734e-02, -5.7953e-02]],\n",
       "\n",
       "         [[ 5.7454e-02,  1.6489e-02, -9.7914e-02, -7.7265e-02,  4.9201e-02],\n",
       "          [ 7.7172e-02, -4.0404e-02, -3.6837e-02,  6.4867e-02,  8.9419e-03],\n",
       "          [-1.1560e-02,  5.0735e-02,  1.0848e-05, -7.1778e-02, -8.6302e-02],\n",
       "          [ 8.7833e-02,  7.9539e-02,  1.1310e-01,  8.8316e-02,  1.0018e-01],\n",
       "          [-9.2219e-02,  1.1471e-01,  2.8214e-02,  3.9151e-02, -1.3620e-02]],\n",
       "\n",
       "         [[ 6.2634e-03,  8.3715e-02,  1.0549e-01,  9.4185e-02, -8.3018e-02],\n",
       "          [ 3.7280e-02,  7.8164e-02, -6.2338e-02,  1.0558e-01,  3.9392e-02],\n",
       "          [-3.6968e-02,  4.5117e-02,  5.4776e-02,  8.8828e-02,  2.1327e-02],\n",
       "          [ 7.9802e-02,  8.2034e-02,  2.2100e-02, -6.7937e-02,  2.9267e-02],\n",
       "          [-9.8278e-02, -1.0588e-01,  7.1954e-02,  4.0841e-02,  4.8872e-02]]],\n",
       "\n",
       "\n",
       "        [[[-9.4402e-02,  8.7678e-02, -8.3204e-02,  1.1496e-01, -1.0720e-01],\n",
       "          [-1.7708e-02, -1.1143e-01,  4.9168e-02, -1.1169e-01,  1.3250e-03],\n",
       "          [-9.6324e-02,  1.0987e-01,  1.0323e-01, -3.7605e-02,  6.7869e-02],\n",
       "          [ 8.6383e-02, -1.2214e-02, -5.8074e-02, -1.5091e-02,  2.4343e-02],\n",
       "          [-8.8799e-03,  2.6577e-02,  8.5716e-02,  3.8562e-02,  4.8246e-02]],\n",
       "\n",
       "         [[ 3.0246e-02, -4.4327e-02,  2.6349e-02,  9.7613e-02, -1.1110e-01],\n",
       "          [-6.2260e-02, -6.9127e-02,  4.7314e-03,  7.5843e-02,  3.4543e-03],\n",
       "          [ 2.2470e-02, -6.4200e-02,  5.1350e-02,  6.0025e-02, -4.3156e-02],\n",
       "          [ 4.9894e-03, -8.1031e-02,  5.2565e-02, -1.0503e-02,  1.0928e-01],\n",
       "          [ 6.4272e-02,  5.2017e-03,  5.4144e-02, -6.8027e-02, -1.0083e-01]],\n",
       "\n",
       "         [[ 9.3914e-02, -2.2732e-02, -9.6490e-02,  2.2249e-02,  1.0713e-01],\n",
       "          [ 8.2680e-02,  7.2541e-02,  4.1088e-02,  4.3589e-02,  2.5013e-02],\n",
       "          [ 4.1342e-02,  5.9577e-03, -1.0496e-01,  2.2947e-02,  1.1135e-01],\n",
       "          [ 9.3612e-03,  1.1246e-01,  2.4033e-02,  1.5581e-04,  8.8992e-02],\n",
       "          [-2.0956e-02,  7.3916e-02,  2.9446e-02,  1.0787e-01,  4.6614e-02]]]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1.state_dict()['conv1.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_step(model_1, model_2):\n",
    "    models_differ = 0\n",
    "    for key_item_1, key_item_2 in zip(model_1.state_dict().items(), model_2.state_dict().items()):\n",
    "        print(key_item_1, key_item_2)\n",
    "#         if torch.equal(key_item_1[1], key_item_2[1]):\n",
    "#             pass\n",
    "#         else:\n",
    "#             models_differ += 1\n",
    "#             if (key_item_1[0] == key_item_2[0]):\n",
    "#                 print('Mismtach found at', key_item_1[0])\n",
    "#             else:\n",
    "#                 raise Exception\n",
    "#     if models_differ == 0:\n",
    "#         print('Models match perfectly! :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('conv1.weight', tensor([[[[ 0.0130,  0.0487, -0.0007, -0.0418, -0.0490],\n",
      "          [-0.0815,  0.0834,  0.1128, -0.0641,  0.0667],\n",
      "          [-0.1082, -0.0206,  0.1079,  0.0726,  0.0170],\n",
      "          [-0.0027, -0.0938, -0.0903, -0.0846,  0.0003],\n",
      "          [-0.0806,  0.0993, -0.0739, -0.0545,  0.0224]],\n",
      "\n",
      "         [[ 0.0081, -0.0035, -0.0518, -0.0646, -0.0404],\n",
      "          [ 0.0127, -0.1079, -0.0311,  0.0028, -0.0010],\n",
      "          [ 0.1086, -0.0731,  0.0188,  0.1117, -0.0989],\n",
      "          [-0.1100,  0.0111,  0.0021, -0.1002, -0.1149],\n",
      "          [-0.0516, -0.0739,  0.0003,  0.0662,  0.0150]],\n",
      "\n",
      "         [[-0.0826, -0.1030,  0.0145, -0.0018, -0.0967],\n",
      "          [ 0.0610, -0.1120, -0.0665, -0.1130,  0.0379],\n",
      "          [-0.0887,  0.0541, -0.1122,  0.0414,  0.0284],\n",
      "          [-0.0619,  0.0329,  0.0286, -0.0768,  0.0395],\n",
      "          [-0.0836,  0.0429,  0.0007,  0.0225, -0.0601]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0949, -0.0688,  0.0087, -0.0765, -0.0997],\n",
      "          [-0.0094,  0.0516, -0.1153, -0.0408,  0.0819],\n",
      "          [-0.0998,  0.0456, -0.0178,  0.0794, -0.0342],\n",
      "          [ 0.0605,  0.0344, -0.0674,  0.0454,  0.0766],\n",
      "          [-0.0524, -0.0848, -0.0433, -0.0786,  0.0304]],\n",
      "\n",
      "         [[-0.0075,  0.0551, -0.0412, -0.0189,  0.0899],\n",
      "          [-0.0180,  0.1042, -0.0091, -0.0198, -0.0922],\n",
      "          [ 0.0158,  0.0696,  0.0197, -0.0253,  0.0377],\n",
      "          [ 0.0562,  0.1001,  0.0391,  0.0538, -0.0773],\n",
      "          [-0.0202,  0.0134, -0.1154, -0.0131,  0.0280]],\n",
      "\n",
      "         [[ 0.0182,  0.0794,  0.0949,  0.0502,  0.0934],\n",
      "          [-0.0403, -0.0683,  0.0922, -0.0891, -0.0568],\n",
      "          [ 0.0100,  0.0617, -0.0234, -0.0606,  0.0685],\n",
      "          [-0.0897,  0.0049, -0.0848, -0.1064, -0.0034],\n",
      "          [ 0.0267,  0.0876, -0.0578, -0.0653, -0.0946]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0303, -0.1011,  0.0974,  0.0268,  0.0625],\n",
      "          [-0.0420,  0.0929, -0.0502,  0.0141, -0.0666],\n",
      "          [-0.0590, -0.0199, -0.0471,  0.0106, -0.1116],\n",
      "          [ 0.0279,  0.0093,  0.0479,  0.0350,  0.0828],\n",
      "          [ 0.0595, -0.0120,  0.0867,  0.0010, -0.0216]],\n",
      "\n",
      "         [[-0.0421, -0.0850,  0.0546, -0.0440, -0.0358],\n",
      "          [-0.1070, -0.0167,  0.0103, -0.1031,  0.0049],\n",
      "          [-0.0922, -0.0638,  0.0363, -0.1036, -0.0723],\n",
      "          [ 0.0008, -0.0860, -0.0420, -0.1125, -0.1114],\n",
      "          [ 0.0122, -0.0391, -0.1119, -0.0569, -0.0066]],\n",
      "\n",
      "         [[-0.1087, -0.1089, -0.0588,  0.0021, -0.0275],\n",
      "          [ 0.1002, -0.1093,  0.0605,  0.0157, -0.0019],\n",
      "          [ 0.0134,  0.0491, -0.0872,  0.0854,  0.1049],\n",
      "          [-0.0142, -0.0648, -0.1035,  0.0896,  0.0351],\n",
      "          [-0.1101, -0.1142,  0.0858, -0.0721, -0.1124]]],\n",
      "\n",
      "\n",
      "        [[[-0.0192,  0.0287, -0.0196, -0.1057,  0.1101],\n",
      "          [-0.0750, -0.0443, -0.0086,  0.0110,  0.0628],\n",
      "          [ 0.0775,  0.0335, -0.0140, -0.0790,  0.1053],\n",
      "          [ 0.0985,  0.0915,  0.0525,  0.0973, -0.0505],\n",
      "          [-0.0309, -0.0291, -0.0542,  0.0185, -0.0258]],\n",
      "\n",
      "         [[ 0.0049,  0.0930, -0.0409, -0.0593, -0.0204],\n",
      "          [-0.0994, -0.1040,  0.0574, -0.1130, -0.0448],\n",
      "          [-0.0896,  0.0525, -0.0215,  0.0110, -0.0847],\n",
      "          [ 0.0031, -0.0979,  0.0560,  0.0442, -0.0832],\n",
      "          [ 0.0927, -0.0065, -0.0393, -0.0857,  0.0635]],\n",
      "\n",
      "         [[ 0.0443,  0.1004, -0.0152, -0.0774,  0.0578],\n",
      "          [-0.0018,  0.0378, -0.0774,  0.0581, -0.0884],\n",
      "          [ 0.1055, -0.0899,  0.0157, -0.0555,  0.0228],\n",
      "          [-0.0818, -0.0919, -0.0767, -0.1021,  0.1000],\n",
      "          [-0.1090,  0.0560,  0.0418,  0.0816, -0.0468]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0606, -0.0581,  0.0234, -0.0936, -0.0590],\n",
      "          [ 0.0118,  0.0719,  0.0513,  0.0714,  0.0905],\n",
      "          [ 0.0628, -0.0517, -0.0796,  0.0782, -0.0765],\n",
      "          [-0.0041, -0.0782,  0.0525,  0.0300,  0.0637],\n",
      "          [-0.0772,  0.0927, -0.0735, -0.0883, -0.0147]],\n",
      "\n",
      "         [[ 0.0471, -0.0795,  0.0885,  0.0510,  0.0719],\n",
      "          [ 0.0213, -0.0867, -0.0375,  0.0512,  0.0374],\n",
      "          [ 0.0121, -0.0989,  0.0472, -0.0523,  0.0260],\n",
      "          [ 0.0519,  0.0733, -0.0762, -0.1039, -0.1091],\n",
      "          [-0.0270,  0.0468,  0.0514,  0.0543,  0.0477]],\n",
      "\n",
      "         [[ 0.0179, -0.0684,  0.0364, -0.0367, -0.0531],\n",
      "          [-0.0185, -0.0281, -0.0328, -0.1007,  0.1032],\n",
      "          [-0.0060,  0.0575, -0.0108,  0.0778,  0.1066],\n",
      "          [-0.0644, -0.0393, -0.0253, -0.0450,  0.0777],\n",
      "          [ 0.0207, -0.1051, -0.0031, -0.0018,  0.0089]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0990,  0.0472,  0.0315, -0.0930, -0.0555],\n",
      "          [ 0.0964,  0.0197,  0.0390,  0.0574,  0.0747],\n",
      "          [-0.0296, -0.0888, -0.0655,  0.0608, -0.1034],\n",
      "          [ 0.0119,  0.0806, -0.0692, -0.0418,  0.0696],\n",
      "          [-0.0049,  0.0524,  0.0548, -0.0095, -0.0464]],\n",
      "\n",
      "         [[ 0.0981, -0.0514,  0.0742, -0.0580,  0.0977],\n",
      "          [ 0.1154,  0.0030, -0.0944, -0.1009,  0.1126],\n",
      "          [-0.0106, -0.0831, -0.0555,  0.1077, -0.0630],\n",
      "          [ 0.0914,  0.1060, -0.0956, -0.0598, -0.0440],\n",
      "          [ 0.0200, -0.0220, -0.0991, -0.0045, -0.0371]],\n",
      "\n",
      "         [[-0.0434,  0.0334, -0.0142,  0.0687,  0.0162],\n",
      "          [-0.0890, -0.0993,  0.0707,  0.1062, -0.0800],\n",
      "          [ 0.0667,  0.0702,  0.0960,  0.0686, -0.1067],\n",
      "          [ 0.0279,  0.0873, -0.0632,  0.0644, -0.0569],\n",
      "          [-0.0020, -0.0174,  0.0320,  0.0120,  0.0546]]]])) ('conv1.weight', tensor([[[[ 9.7011e-02, -7.0986e-02, -5.0680e-02,  2.1627e-02, -4.0288e-02],\n",
      "          [ 8.1597e-02, -1.7908e-02, -9.3028e-02,  1.2518e-03, -9.1645e-02],\n",
      "          [ 2.3220e-02,  2.4334e-02, -7.0428e-02,  1.3461e-02,  1.2526e-02],\n",
      "          [-1.0423e-01, -1.6604e-02, -9.5009e-02, -5.6317e-02, -1.1458e-01],\n",
      "          [-7.3696e-02,  9.2810e-02, -6.7467e-02, -4.3678e-02, -6.4489e-03]],\n",
      "\n",
      "         [[-7.7403e-02,  4.7599e-02, -6.7939e-02, -6.1037e-02, -3.6515e-02],\n",
      "          [-5.2274e-02, -3.8494e-02,  1.1365e-01, -2.4925e-02, -8.1308e-02],\n",
      "          [-1.0075e-01,  1.0823e-01,  2.3625e-02,  7.6865e-02, -1.9780e-02],\n",
      "          [ 9.2719e-03,  3.2250e-02,  7.6738e-02, -1.1412e-01, -1.0044e-01],\n",
      "          [ 7.1153e-02, -1.0216e-01, -5.4211e-02,  7.8163e-02, -4.6775e-02]],\n",
      "\n",
      "         [[ 3.1148e-02, -1.1238e-01,  4.9241e-02, -6.2325e-02, -1.0559e-01],\n",
      "          [ 1.1105e-01,  2.1416e-02, -9.6451e-02, -6.6975e-02, -9.0657e-02],\n",
      "          [-5.7376e-02, -3.5508e-02,  1.6550e-02,  8.6849e-02,  9.5923e-02],\n",
      "          [ 7.4250e-02,  6.3212e-02, -9.2907e-02, -1.6288e-02, -7.4885e-02],\n",
      "          [-1.1261e-01,  9.8263e-02, -8.1134e-02, -1.2369e-02,  8.1375e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.6945e-02, -7.5287e-02,  9.7908e-03,  8.6044e-02,  4.6488e-02],\n",
      "          [-2.4314e-02, -7.8554e-02,  3.9658e-02, -2.3563e-02, -9.7361e-02],\n",
      "          [ 8.3038e-02,  5.3385e-02, -1.4057e-03, -6.5836e-02, -1.0997e-01],\n",
      "          [-2.1078e-02,  1.3376e-02, -4.9314e-02,  3.3444e-02,  1.5432e-02],\n",
      "          [ 3.2493e-03,  9.5318e-02, -1.0649e-01, -1.1174e-01,  3.4765e-02]],\n",
      "\n",
      "         [[-9.0219e-02, -5.4670e-03,  3.0253e-02, -5.3186e-02, -7.5512e-02],\n",
      "          [ 1.0220e-01,  1.1328e-01, -8.4383e-02,  1.1212e-01, -5.9861e-03],\n",
      "          [-3.9465e-02, -4.5806e-02, -1.1519e-01,  6.7181e-02, -5.3756e-02],\n",
      "          [-1.4151e-02, -5.4554e-02,  8.7236e-02, -7.8946e-02,  2.0516e-02],\n",
      "          [ 9.3797e-02, -3.1939e-02, -5.9906e-02,  4.1803e-02, -7.5665e-02]],\n",
      "\n",
      "         [[ 7.9067e-02, -1.0829e-02,  3.6126e-02,  5.9646e-03, -2.2042e-02],\n",
      "          [-5.6970e-02, -6.7975e-02,  2.1599e-02, -5.5347e-02,  1.1393e-01],\n",
      "          [ 4.8053e-02, -1.1491e-01,  4.2681e-02,  1.0066e-01,  5.7225e-02],\n",
      "          [ 3.7228e-02, -1.0659e-01, -1.0784e-01,  5.7063e-02, -5.5052e-02],\n",
      "          [ 1.0735e-01,  3.6946e-03,  6.2661e-02, -5.4081e-02,  8.2190e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.3646e-02, -1.2171e-02,  5.1464e-02,  2.0812e-02, -5.3597e-02],\n",
      "          [-2.6933e-02,  8.9427e-02, -1.1733e-02, -8.6958e-02,  8.8319e-02],\n",
      "          [-3.8558e-02, -2.2938e-02,  1.0786e-01,  3.8217e-02, -9.1548e-02],\n",
      "          [ 9.5661e-02,  3.7048e-02, -8.3999e-02, -8.0329e-02, -7.6232e-02],\n",
      "          [ 8.4946e-02, -5.0368e-02,  4.5219e-02, -8.1882e-02,  2.1496e-02]],\n",
      "\n",
      "         [[ 6.5425e-02,  5.0028e-02,  4.7118e-02,  9.4167e-02, -8.8159e-02],\n",
      "          [-7.3232e-02, -3.0179e-02, -6.2756e-02, -9.8577e-02,  8.7076e-02],\n",
      "          [-7.1198e-02,  5.1464e-02,  2.9676e-02,  7.1935e-03, -7.6556e-02],\n",
      "          [ 9.4313e-02, -8.4722e-02,  6.9810e-02, -1.5858e-02, -7.4159e-02],\n",
      "          [-4.3951e-02, -5.2072e-02, -1.1368e-01,  5.5897e-02, -2.9524e-02]],\n",
      "\n",
      "         [[-3.6438e-02, -6.1535e-02, -1.0132e-01, -1.7232e-02, -6.9233e-02],\n",
      "          [-8.2176e-03, -1.1016e-01, -6.0802e-02, -7.3377e-03,  6.4098e-02],\n",
      "          [-1.6209e-02, -1.1228e-01, -7.7566e-02,  1.4592e-02, -2.5569e-02],\n",
      "          [-8.1549e-02, -1.0972e-01, -1.0775e-01,  4.7703e-02,  5.6897e-02],\n",
      "          [-1.4378e-02, -2.3681e-02, -2.2586e-02, -6.9355e-03, -1.0434e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.3762e-02, -1.1216e-01, -6.2957e-03,  5.3578e-02,  1.0666e-01],\n",
      "          [ 1.9817e-02, -4.1498e-02,  7.3873e-02, -3.9436e-02,  6.0440e-02],\n",
      "          [ 6.3668e-02,  3.8557e-02, -6.8636e-03, -7.0644e-02,  9.0610e-02],\n",
      "          [ 7.3761e-02, -6.9710e-02, -3.0957e-03, -1.0710e-01,  7.4123e-03],\n",
      "          [-9.9643e-02, -5.3618e-02,  9.1150e-02, -1.0864e-01, -2.8493e-02]],\n",
      "\n",
      "         [[-4.1852e-02,  1.0692e-02, -1.8428e-02, -8.5635e-02, -2.1865e-02],\n",
      "          [-2.3554e-02,  8.2217e-03,  1.8439e-02, -9.6486e-02, -1.7721e-02],\n",
      "          [ 3.3116e-02,  2.3474e-02,  7.9623e-02, -9.2075e-03, -7.0783e-02],\n",
      "          [-6.4343e-02, -8.1650e-02, -4.2554e-02,  1.4233e-02,  4.8295e-02],\n",
      "          [-1.5718e-02,  4.3258e-02,  3.7946e-03,  5.6153e-03, -1.1379e-01]],\n",
      "\n",
      "         [[ 1.0683e-01, -8.2759e-02, -8.0063e-02,  9.1073e-02, -3.0534e-02],\n",
      "          [ 1.5430e-02, -3.7413e-02,  3.7420e-02,  1.0474e-01, -6.3178e-02],\n",
      "          [ 3.0403e-02,  7.5641e-03,  6.3269e-03, -4.7828e-02,  6.7690e-02],\n",
      "          [-9.6000e-02, -3.4193e-02,  8.4696e-02, -7.6428e-02,  6.0516e-02],\n",
      "          [ 1.2024e-02, -8.6438e-02, -6.9373e-02,  1.0109e-01, -8.7238e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6037e-02,  1.4900e-02,  3.3808e-02, -3.3674e-02, -5.5273e-02],\n",
      "          [-3.8632e-02,  4.4728e-02,  5.7744e-02,  6.7515e-02, -5.8823e-02],\n",
      "          [ 3.6914e-02,  4.8579e-02,  3.3652e-02, -9.3411e-02, -8.0249e-02],\n",
      "          [-4.3482e-02, -9.7915e-02, -1.6541e-02, -6.9479e-02, -4.2139e-02],\n",
      "          [ 2.2148e-02, -1.1390e-02,  6.9588e-02, -6.6734e-02, -5.7953e-02]],\n",
      "\n",
      "         [[ 5.7454e-02,  1.6489e-02, -9.7914e-02, -7.7265e-02,  4.9201e-02],\n",
      "          [ 7.7172e-02, -4.0404e-02, -3.6837e-02,  6.4867e-02,  8.9419e-03],\n",
      "          [-1.1560e-02,  5.0735e-02,  1.0848e-05, -7.1778e-02, -8.6302e-02],\n",
      "          [ 8.7833e-02,  7.9539e-02,  1.1310e-01,  8.8316e-02,  1.0018e-01],\n",
      "          [-9.2219e-02,  1.1471e-01,  2.8214e-02,  3.9151e-02, -1.3620e-02]],\n",
      "\n",
      "         [[ 6.2634e-03,  8.3715e-02,  1.0549e-01,  9.4185e-02, -8.3018e-02],\n",
      "          [ 3.7280e-02,  7.8164e-02, -6.2338e-02,  1.0558e-01,  3.9392e-02],\n",
      "          [-3.6968e-02,  4.5117e-02,  5.4776e-02,  8.8828e-02,  2.1327e-02],\n",
      "          [ 7.9802e-02,  8.2034e-02,  2.2100e-02, -6.7937e-02,  2.9267e-02],\n",
      "          [-9.8278e-02, -1.0588e-01,  7.1954e-02,  4.0841e-02,  4.8872e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.4402e-02,  8.7678e-02, -8.3204e-02,  1.1496e-01, -1.0720e-01],\n",
      "          [-1.7708e-02, -1.1143e-01,  4.9168e-02, -1.1169e-01,  1.3250e-03],\n",
      "          [-9.6324e-02,  1.0987e-01,  1.0323e-01, -3.7605e-02,  6.7869e-02],\n",
      "          [ 8.6383e-02, -1.2214e-02, -5.8074e-02, -1.5091e-02,  2.4343e-02],\n",
      "          [-8.8799e-03,  2.6577e-02,  8.5716e-02,  3.8562e-02,  4.8246e-02]],\n",
      "\n",
      "         [[ 3.0246e-02, -4.4327e-02,  2.6349e-02,  9.7613e-02, -1.1110e-01],\n",
      "          [-6.2260e-02, -6.9127e-02,  4.7314e-03,  7.5843e-02,  3.4543e-03],\n",
      "          [ 2.2470e-02, -6.4200e-02,  5.1350e-02,  6.0025e-02, -4.3156e-02],\n",
      "          [ 4.9894e-03, -8.1031e-02,  5.2565e-02, -1.0503e-02,  1.0928e-01],\n",
      "          [ 6.4272e-02,  5.2017e-03,  5.4144e-02, -6.8027e-02, -1.0083e-01]],\n",
      "\n",
      "         [[ 9.3914e-02, -2.2732e-02, -9.6490e-02,  2.2249e-02,  1.0713e-01],\n",
      "          [ 8.2680e-02,  7.2541e-02,  4.1088e-02,  4.3589e-02,  2.5013e-02],\n",
      "          [ 4.1342e-02,  5.9577e-03, -1.0496e-01,  2.2947e-02,  1.1135e-01],\n",
      "          [ 9.3612e-03,  1.1246e-01,  2.4033e-02,  1.5581e-04,  8.8992e-02],\n",
      "          [-2.0956e-02,  7.3916e-02,  2.9446e-02,  1.0787e-01,  4.6614e-02]]]]))\n",
      "('conv1.bias', tensor([ 0.0921,  0.0876, -0.0642,  0.0395, -0.0451, -0.0459])) ('conv1.bias', tensor([ 0.0986, -0.0766,  0.0861,  0.0275,  0.0117, -0.1062]))\n",
      "('conv2.weight', tensor([[[[-0.0306, -0.0564, -0.0090,  0.0127, -0.0320],\n",
      "          [-0.0291,  0.0419, -0.0703,  0.0361,  0.0024],\n",
      "          [-0.0540, -0.0334, -0.0122,  0.0014, -0.0581],\n",
      "          [-0.0381, -0.0720,  0.0279,  0.0115,  0.0448],\n",
      "          [ 0.0604, -0.0810, -0.0005,  0.0541, -0.0183]],\n",
      "\n",
      "         [[-0.0061, -0.0097,  0.0552,  0.0671, -0.0007],\n",
      "          [ 0.0563, -0.0045, -0.0153,  0.0135, -0.0075],\n",
      "          [-0.0070,  0.0213,  0.0026, -0.0189, -0.0470],\n",
      "          [ 0.0062,  0.0731,  0.0576, -0.0497,  0.0053],\n",
      "          [ 0.0554,  0.0187,  0.0641,  0.0468,  0.0778]],\n",
      "\n",
      "         [[ 0.0404,  0.0179, -0.0106, -0.0737, -0.0325],\n",
      "          [ 0.0518, -0.0417, -0.0428, -0.0677, -0.0124],\n",
      "          [-0.0196,  0.0181, -0.0733, -0.0208, -0.0665],\n",
      "          [-0.0529, -0.0043, -0.0355,  0.0565,  0.0249],\n",
      "          [-0.0090,  0.0298, -0.0575,  0.0677, -0.0792]],\n",
      "\n",
      "         [[ 0.0268,  0.0472, -0.0693, -0.0224, -0.0679],\n",
      "          [-0.0451,  0.0089, -0.0629,  0.0331,  0.0701],\n",
      "          [-0.0372,  0.0194, -0.0061,  0.0547,  0.0226],\n",
      "          [-0.0717,  0.0068, -0.0141,  0.0169,  0.0527],\n",
      "          [ 0.0305,  0.0019,  0.0705, -0.0601, -0.0110]],\n",
      "\n",
      "         [[ 0.0237, -0.0318, -0.0537, -0.0645, -0.0597],\n",
      "          [-0.0099, -0.0027, -0.0273, -0.0060, -0.0040],\n",
      "          [ 0.0295,  0.0667, -0.0517,  0.0625,  0.0662],\n",
      "          [-0.0393,  0.0615,  0.0057, -0.0108, -0.0810],\n",
      "          [ 0.0269, -0.0133, -0.0160,  0.0253,  0.0017]],\n",
      "\n",
      "         [[ 0.0758,  0.0090,  0.0175, -0.0683,  0.0632],\n",
      "          [-0.0558,  0.0382, -0.0063,  0.0097, -0.0526],\n",
      "          [-0.0476, -0.0213,  0.0687,  0.0099,  0.0514],\n",
      "          [-0.0682, -0.0514,  0.0577, -0.0006,  0.0747],\n",
      "          [-0.0243, -0.0619,  0.0692, -0.0411, -0.0234]]],\n",
      "\n",
      "\n",
      "        [[[-0.0374,  0.0814, -0.0360,  0.0660, -0.0236],\n",
      "          [ 0.0800,  0.0365,  0.0217, -0.0756,  0.0223],\n",
      "          [ 0.0769, -0.0266,  0.0611,  0.0717, -0.0035],\n",
      "          [-0.0542,  0.0544,  0.0719,  0.0707, -0.0801],\n",
      "          [-0.0640, -0.0525, -0.0727, -0.0397,  0.0430]],\n",
      "\n",
      "         [[ 0.0336, -0.0196,  0.0500, -0.0370,  0.0029],\n",
      "          [-0.0647, -0.0355,  0.0680,  0.0077, -0.0474],\n",
      "          [ 0.0260,  0.0276, -0.0524, -0.0727,  0.0689],\n",
      "          [-0.0025, -0.0372, -0.0769,  0.0244, -0.0084],\n",
      "          [-0.0368, -0.0250, -0.0503, -0.0040,  0.0453]],\n",
      "\n",
      "         [[ 0.0315,  0.0625,  0.0439, -0.0604, -0.0633],\n",
      "          [ 0.0146, -0.0065, -0.0741, -0.0278, -0.0631],\n",
      "          [-0.0649,  0.0512, -0.0518,  0.0645,  0.0752],\n",
      "          [-0.0463,  0.0221,  0.0352, -0.0722,  0.0546],\n",
      "          [ 0.0552,  0.0204, -0.0392,  0.0524,  0.0753]],\n",
      "\n",
      "         [[-0.0346,  0.0186, -0.0670, -0.0497, -0.0352],\n",
      "          [-0.0322, -0.0297, -0.0143, -0.0569, -0.0463],\n",
      "          [-0.0104, -0.0610,  0.0106,  0.0041,  0.0325],\n",
      "          [ 0.0284, -0.0755,  0.0499, -0.0655,  0.0783],\n",
      "          [ 0.0745, -0.0388, -0.0141, -0.0703, -0.0179]],\n",
      "\n",
      "         [[-0.0549,  0.0630, -0.0658, -0.0398, -0.0033],\n",
      "          [ 0.0073,  0.0476, -0.0476, -0.0180,  0.0727],\n",
      "          [ 0.0366,  0.0238,  0.0609, -0.0068,  0.0583],\n",
      "          [ 0.0444, -0.0080, -0.0254, -0.0020, -0.0732],\n",
      "          [ 0.0561,  0.0090, -0.0479, -0.0533, -0.0808]],\n",
      "\n",
      "         [[-0.0126,  0.0727, -0.0057,  0.0807, -0.0322],\n",
      "          [-0.0136,  0.0315, -0.0332, -0.0247, -0.0023],\n",
      "          [-0.0314, -0.0663, -0.0636, -0.0593, -0.0405],\n",
      "          [ 0.0075,  0.0268,  0.0717, -0.0317, -0.0459],\n",
      "          [-0.0019, -0.0692, -0.0681, -0.0317, -0.0480]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0130,  0.0486,  0.0761, -0.0470, -0.0159],\n",
      "          [ 0.0742,  0.0742, -0.0702,  0.0396, -0.0217],\n",
      "          [ 0.0448,  0.0053,  0.0063, -0.0785,  0.0289],\n",
      "          [-0.0775,  0.0618,  0.0095, -0.0393, -0.0804],\n",
      "          [ 0.0350, -0.0612,  0.0119,  0.0099, -0.0555]],\n",
      "\n",
      "         [[-0.0735,  0.0372, -0.0814,  0.0650, -0.0813],\n",
      "          [ 0.0639, -0.0310,  0.0775, -0.0155,  0.0361],\n",
      "          [-0.0678, -0.0542, -0.0792, -0.0388, -0.0620],\n",
      "          [ 0.0629,  0.0076, -0.0390,  0.0542, -0.0432],\n",
      "          [ 0.0531,  0.0023, -0.0698,  0.0220,  0.0317]],\n",
      "\n",
      "         [[-0.0446,  0.0444, -0.0621,  0.0393,  0.0739],\n",
      "          [ 0.0264, -0.0018, -0.0170,  0.0076,  0.0722],\n",
      "          [ 0.0146, -0.0349,  0.0351,  0.0580,  0.0368],\n",
      "          [-0.0764,  0.0138,  0.0570,  0.0494,  0.0239],\n",
      "          [ 0.0030, -0.0340,  0.0026,  0.0798,  0.0540]],\n",
      "\n",
      "         [[-0.0462,  0.0364, -0.0529,  0.0173,  0.0030],\n",
      "          [ 0.0313, -0.0736, -0.0760, -0.0293, -0.0006],\n",
      "          [-0.0763, -0.0223, -0.0215,  0.0068, -0.0595],\n",
      "          [-0.0065, -0.0492,  0.0699,  0.0394,  0.0323],\n",
      "          [ 0.0445, -0.0457,  0.0425,  0.0645, -0.0041]],\n",
      "\n",
      "         [[-0.0783, -0.0125, -0.0110, -0.0322, -0.0249],\n",
      "          [-0.0483, -0.0702, -0.0342,  0.0070,  0.0201],\n",
      "          [ 0.0551,  0.0242, -0.0419,  0.0329, -0.0479],\n",
      "          [ 0.0734, -0.0632,  0.0802, -0.0566, -0.0250],\n",
      "          [ 0.0345,  0.0564,  0.0633,  0.0555, -0.0036]],\n",
      "\n",
      "         [[-0.0017, -0.0196,  0.0193,  0.0714,  0.0658],\n",
      "          [-0.0204,  0.0087, -0.0466,  0.0224, -0.0694],\n",
      "          [ 0.0816, -0.0683,  0.0017, -0.0361, -0.0346],\n",
      "          [-0.0764, -0.0727,  0.0725, -0.0753, -0.0558],\n",
      "          [ 0.0634,  0.0400, -0.0430, -0.0285,  0.0763]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0336, -0.0390,  0.0064, -0.0400,  0.0082],\n",
      "          [-0.0355, -0.0374, -0.0366, -0.0389,  0.0758],\n",
      "          [ 0.0294,  0.0063, -0.0384,  0.0043,  0.0002],\n",
      "          [-0.0292, -0.0739, -0.0481, -0.0256, -0.0050],\n",
      "          [ 0.0574, -0.0369, -0.0495,  0.0653, -0.0781]],\n",
      "\n",
      "         [[-0.0631,  0.0704, -0.0730, -0.0794, -0.0473],\n",
      "          [-0.0152, -0.0524, -0.0595, -0.0154,  0.0422],\n",
      "          [ 0.0802,  0.0399,  0.0598,  0.0383, -0.0481],\n",
      "          [ 0.0359, -0.0128,  0.0692,  0.0537, -0.0538],\n",
      "          [ 0.0210, -0.0438,  0.0737,  0.0265, -0.0358]],\n",
      "\n",
      "         [[ 0.0161, -0.0718, -0.0484,  0.0335,  0.0706],\n",
      "          [-0.0037,  0.0467, -0.0785, -0.0377, -0.0194],\n",
      "          [ 0.0569, -0.0555, -0.0092,  0.0191, -0.0581],\n",
      "          [-0.0815, -0.0365,  0.0609,  0.0015,  0.0557],\n",
      "          [ 0.0489,  0.0302, -0.0539,  0.0687, -0.0146]],\n",
      "\n",
      "         [[-0.0472,  0.0428,  0.0001, -0.0344, -0.0812],\n",
      "          [-0.0660,  0.0613,  0.0809, -0.0722, -0.0289],\n",
      "          [-0.0564,  0.0083, -0.0097, -0.0389, -0.0367],\n",
      "          [-0.0039, -0.0274, -0.0100, -0.0341, -0.0210],\n",
      "          [ 0.0498,  0.0550,  0.0750, -0.0222,  0.0582]],\n",
      "\n",
      "         [[ 0.0695, -0.0237, -0.0294, -0.0067,  0.0452],\n",
      "          [-0.0070,  0.0503, -0.0810, -0.0016, -0.0022],\n",
      "          [ 0.0757,  0.0240, -0.0532, -0.0138, -0.0329],\n",
      "          [ 0.0358, -0.0493,  0.0652,  0.0813,  0.0134],\n",
      "          [ 0.0522,  0.0513,  0.0642, -0.0487, -0.0468]],\n",
      "\n",
      "         [[ 0.0431,  0.0022, -0.0511,  0.0338,  0.0189],\n",
      "          [-0.0214,  0.0455, -0.0364,  0.0109,  0.0673],\n",
      "          [-0.0193,  0.0108,  0.0201, -0.0578, -0.0308],\n",
      "          [ 0.0225, -0.0132,  0.0550,  0.0160,  0.0169],\n",
      "          [-0.0614, -0.0157,  0.0467, -0.0445, -0.0511]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0024, -0.0577, -0.0247,  0.0194,  0.0374],\n",
      "          [-0.0373,  0.0549, -0.0276,  0.0651,  0.0659],\n",
      "          [-0.0297,  0.0533, -0.0694, -0.0682,  0.0816],\n",
      "          [-0.0007,  0.0638, -0.0809, -0.0294,  0.0013],\n",
      "          [ 0.0800, -0.0119,  0.0665,  0.0153,  0.0157]],\n",
      "\n",
      "         [[ 0.0415,  0.0788, -0.0034,  0.0030,  0.0300],\n",
      "          [-0.0474,  0.0379,  0.0042,  0.0698,  0.0707],\n",
      "          [-0.0094, -0.0176, -0.0569, -0.0155,  0.0650],\n",
      "          [-0.0516, -0.0185,  0.0668, -0.0131, -0.0379],\n",
      "          [-0.0437,  0.0406, -0.0582, -0.0810, -0.0523]],\n",
      "\n",
      "         [[-0.0610, -0.0169, -0.0470,  0.0484, -0.0647],\n",
      "          [-0.0486, -0.0344,  0.0121, -0.0686, -0.0266],\n",
      "          [ 0.0618, -0.0563,  0.0246, -0.0552,  0.0523],\n",
      "          [-0.0165,  0.0150,  0.0370,  0.0530,  0.0451],\n",
      "          [ 0.0604,  0.0428, -0.0450,  0.0657, -0.0776]],\n",
      "\n",
      "         [[ 0.0595, -0.0743,  0.0730,  0.0383,  0.0787],\n",
      "          [-0.0593,  0.0052, -0.0509, -0.0355,  0.0005],\n",
      "          [-0.0527, -0.0595,  0.0577, -0.0701,  0.0718],\n",
      "          [-0.0034, -0.0438,  0.0758,  0.0469, -0.0110],\n",
      "          [ 0.0436,  0.0352, -0.0631, -0.0780,  0.0763]],\n",
      "\n",
      "         [[-0.0028, -0.0121,  0.0071,  0.0741, -0.0775],\n",
      "          [-0.0356, -0.0464,  0.0337,  0.0387,  0.0449],\n",
      "          [-0.0674, -0.0373, -0.0225, -0.0575,  0.0141],\n",
      "          [-0.0078,  0.0581,  0.0571, -0.0771, -0.0245],\n",
      "          [-0.0500, -0.0154,  0.0411,  0.0187,  0.0336]],\n",
      "\n",
      "         [[ 0.0371,  0.0164, -0.0556,  0.0558,  0.0786],\n",
      "          [-0.0328,  0.0172, -0.0791,  0.0124,  0.0356],\n",
      "          [-0.0719,  0.0007,  0.0723, -0.0181,  0.0673],\n",
      "          [-0.0536,  0.0707, -0.0590,  0.0787,  0.0042],\n",
      "          [-0.0152,  0.0575, -0.0690, -0.0786, -0.0709]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0515,  0.0242,  0.0591, -0.0510,  0.0375],\n",
      "          [-0.0243, -0.0442,  0.0307, -0.0435,  0.0426],\n",
      "          [-0.0126,  0.0620, -0.0070,  0.0198, -0.0521],\n",
      "          [ 0.0810,  0.0057,  0.0687, -0.0384,  0.0669],\n",
      "          [ 0.0439,  0.0254,  0.0156,  0.0520, -0.0765]],\n",
      "\n",
      "         [[-0.0197,  0.0335,  0.0621, -0.0481, -0.0771],\n",
      "          [-0.0082,  0.0578,  0.0464,  0.0813,  0.0792],\n",
      "          [-0.0690, -0.0724, -0.0203,  0.0594, -0.0724],\n",
      "          [ 0.0118, -0.0217, -0.0799, -0.0026, -0.0212],\n",
      "          [-0.0310,  0.0541, -0.0652,  0.0758, -0.0596]],\n",
      "\n",
      "         [[ 0.0385, -0.0406,  0.0620,  0.0650,  0.0676],\n",
      "          [-0.0156,  0.0716,  0.0007, -0.0165, -0.0473],\n",
      "          [ 0.0066,  0.0423, -0.0263,  0.0659, -0.0668],\n",
      "          [ 0.0027, -0.0590,  0.0186, -0.0548,  0.0050],\n",
      "          [-0.0133, -0.0249,  0.0236,  0.0743, -0.0183]],\n",
      "\n",
      "         [[-0.0533,  0.0043,  0.0757,  0.0396,  0.0214],\n",
      "          [ 0.0165, -0.0131, -0.0121, -0.0666,  0.0256],\n",
      "          [ 0.0280,  0.0800, -0.0162,  0.0715, -0.0194],\n",
      "          [-0.0388,  0.0108, -0.0129, -0.0687,  0.0136],\n",
      "          [-0.0432, -0.0488,  0.0252, -0.0725, -0.0681]],\n",
      "\n",
      "         [[-0.0616,  0.0741,  0.0376, -0.0706, -0.0574],\n",
      "          [ 0.0532, -0.0007, -0.0711,  0.0741, -0.0043],\n",
      "          [-0.0538,  0.0770,  0.0564,  0.0164,  0.0684],\n",
      "          [-0.0392,  0.0683, -0.0657,  0.0680, -0.0590],\n",
      "          [ 0.0275, -0.0201,  0.0755,  0.0594, -0.0439]],\n",
      "\n",
      "         [[-0.0561,  0.0234, -0.0282,  0.0612, -0.0010],\n",
      "          [ 0.0376,  0.0008,  0.0087, -0.0015, -0.0400],\n",
      "          [ 0.0691,  0.0446,  0.0743, -0.0725,  0.0616],\n",
      "          [-0.0356, -0.0774, -0.0751,  0.0748,  0.0495],\n",
      "          [ 0.0799, -0.0198,  0.0427,  0.0129, -0.0411]]]])) ('conv2.weight', tensor([[[[-5.7290e-02,  6.8128e-03, -7.4447e-03, -6.7371e-02, -5.4627e-02],\n",
      "          [-2.7375e-02,  3.5138e-02,  2.0347e-02,  3.2788e-02,  1.1710e-02],\n",
      "          [-8.1552e-02, -4.9661e-02,  5.2038e-02,  5.9224e-02, -1.7743e-02],\n",
      "          [-8.0904e-02, -5.5894e-02, -5.6589e-02,  7.8616e-02, -1.9430e-02],\n",
      "          [ 4.8639e-02,  2.9056e-02,  1.1604e-02,  6.8857e-02, -1.3445e-02]],\n",
      "\n",
      "         [[ 3.6426e-02,  2.7727e-03,  6.0624e-02, -5.0477e-02,  1.2648e-02],\n",
      "          [-7.0216e-02, -6.9328e-02,  7.9993e-02,  2.8355e-02, -7.4818e-02],\n",
      "          [ 3.3243e-02,  6.0826e-02, -7.3032e-02, -3.9752e-02,  6.4692e-02],\n",
      "          [ 6.5438e-02,  7.9340e-02,  3.7718e-02, -1.9865e-02, -1.7649e-03],\n",
      "          [-6.5762e-02,  4.8459e-02, -3.8603e-02, -6.4088e-02, -9.6165e-05]],\n",
      "\n",
      "         [[ 6.4442e-02,  5.8110e-02,  1.8871e-02, -2.8833e-02,  3.1164e-02],\n",
      "          [ 6.3061e-04,  2.0304e-02,  7.2930e-02,  6.9844e-02,  6.6727e-02],\n",
      "          [-7.3182e-02, -1.1954e-02, -1.9102e-03,  8.1610e-02,  2.0953e-02],\n",
      "          [ 2.8144e-02,  5.2361e-02,  9.7911e-03,  6.3317e-02, -3.3164e-02],\n",
      "          [ 6.5433e-02,  6.8325e-02,  4.6286e-02, -5.0664e-02, -1.2363e-02]],\n",
      "\n",
      "         [[-2.4180e-02,  2.9369e-02, -9.1792e-03, -3.0313e-02, -3.6099e-02],\n",
      "          [ 6.2491e-02, -1.0483e-02, -4.8324e-02, -2.2770e-02,  4.9270e-02],\n",
      "          [ 4.1869e-02, -4.6052e-02,  3.4596e-02, -7.8105e-02,  5.6155e-02],\n",
      "          [-1.7711e-02, -3.0356e-02, -7.4739e-02, -1.3244e-02, -7.0709e-02],\n",
      "          [ 2.5731e-02, -7.9121e-02, -8.0144e-02,  5.2443e-02, -2.9045e-02]],\n",
      "\n",
      "         [[-3.4141e-02, -2.7209e-02,  3.8351e-02,  2.8602e-02, -7.6240e-02],\n",
      "          [-7.2284e-02, -3.9865e-02, -6.7719e-02, -6.8799e-03,  2.6541e-02],\n",
      "          [ 2.0061e-02, -2.2822e-02, -6.1642e-04, -2.6593e-02, -4.0755e-02],\n",
      "          [-7.6022e-02,  7.7064e-02,  4.7712e-02,  1.0720e-02, -2.1760e-02],\n",
      "          [-4.2447e-02,  4.8104e-02,  3.8414e-02, -4.1944e-02, -4.7472e-02]],\n",
      "\n",
      "         [[-7.1765e-02, -4.2427e-02, -3.0864e-02, -4.5881e-02,  1.2791e-02],\n",
      "          [ 3.1112e-02, -1.7819e-02,  2.0453e-03, -4.6660e-03, -7.4020e-02],\n",
      "          [ 7.0266e-02,  4.6629e-02, -8.5256e-03,  4.4227e-02,  2.0417e-02],\n",
      "          [ 3.7685e-02,  9.7156e-03, -8.0855e-02, -2.0609e-02,  7.7751e-02],\n",
      "          [ 8.0899e-02,  5.8915e-02, -5.7545e-03,  2.1239e-02,  2.5474e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7038e-02,  2.5262e-02,  2.9746e-02,  7.6311e-02,  1.6948e-02],\n",
      "          [-5.3362e-02,  3.9833e-02,  5.2345e-02, -5.0188e-02,  4.1252e-02],\n",
      "          [-5.8995e-02,  1.1168e-02, -8.0471e-02, -3.3022e-02,  6.5579e-02],\n",
      "          [ 5.1908e-02,  5.5339e-02, -4.1177e-02,  1.4391e-02,  1.6652e-02],\n",
      "          [-2.9036e-02, -4.8098e-02,  1.6410e-02,  7.1230e-02,  6.5908e-02]],\n",
      "\n",
      "         [[ 3.4789e-02, -1.9274e-03,  4.5628e-03, -1.4380e-06, -6.2512e-02],\n",
      "          [-8.2614e-03,  4.5300e-02, -4.3769e-02,  8.0316e-02,  4.3037e-02],\n",
      "          [-5.9993e-02,  8.4823e-03, -6.8374e-02,  3.9286e-02, -6.5858e-02],\n",
      "          [-4.9870e-02,  3.0983e-02, -3.1789e-03, -3.9969e-02,  4.5108e-02],\n",
      "          [ 6.6497e-02,  1.1963e-02, -2.9592e-02, -2.7986e-02, -8.1279e-02]],\n",
      "\n",
      "         [[-7.8030e-02,  5.8418e-02,  6.6281e-02,  4.7573e-02, -7.5298e-02],\n",
      "          [-1.3526e-02, -6.2834e-02,  1.2868e-02, -6.9491e-02,  7.6054e-03],\n",
      "          [ 7.5241e-02,  1.7680e-02,  7.0739e-03, -1.6694e-02,  2.7694e-02],\n",
      "          [ 4.6612e-02, -4.8312e-02,  1.0262e-02, -7.7752e-02,  1.0860e-02],\n",
      "          [ 2.6608e-02,  1.2854e-02, -1.7554e-02, -5.4497e-02, -3.4267e-02]],\n",
      "\n",
      "         [[ 6.4336e-02,  6.1281e-02,  7.6588e-02, -3.1785e-02,  1.6804e-02],\n",
      "          [ 2.4261e-02, -6.5205e-02,  2.0855e-02,  4.8761e-02, -3.7973e-02],\n",
      "          [ 2.0780e-02,  5.8900e-02,  2.1798e-02, -5.5903e-02,  7.5512e-02],\n",
      "          [-7.7954e-02,  5.3461e-02,  3.1618e-02,  5.6525e-02, -6.8347e-02],\n",
      "          [-4.1191e-02,  7.0182e-02, -6.9438e-02, -1.2074e-04,  6.5041e-02]],\n",
      "\n",
      "         [[-4.1580e-02, -4.6799e-02, -5.8388e-03, -6.5729e-02, -8.1417e-02],\n",
      "          [-3.9440e-02,  3.6088e-02, -7.4277e-02,  1.3112e-02, -4.9445e-02],\n",
      "          [ 9.7301e-03,  6.9460e-02,  2.8053e-02,  1.0356e-02, -7.5397e-02],\n",
      "          [ 5.5013e-02, -2.0160e-02, -1.9734e-02, -2.8475e-03,  8.0149e-02],\n",
      "          [ 6.4011e-02,  6.7163e-02, -1.1056e-02,  5.1988e-02, -5.4960e-02]],\n",
      "\n",
      "         [[-2.1316e-02, -3.6928e-02, -2.9895e-02, -6.4597e-02,  2.4495e-02],\n",
      "          [-1.0785e-02,  6.3382e-02, -2.3388e-02,  4.1285e-02, -2.5147e-02],\n",
      "          [-3.6456e-02, -7.4238e-02,  6.3850e-03, -7.4027e-02, -1.6198e-02],\n",
      "          [-6.4487e-03, -4.3690e-02,  7.6516e-02,  3.0990e-02, -4.6528e-02],\n",
      "          [ 1.3970e-02, -6.2627e-03,  6.6046e-02,  7.6675e-02,  3.9379e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6219e-02,  2.7618e-02, -7.7201e-02,  2.0338e-02, -5.9618e-02],\n",
      "          [ 1.3484e-02, -8.0433e-02,  2.6279e-03, -7.6698e-02,  3.0559e-02],\n",
      "          [ 4.0515e-02, -1.4529e-02, -4.5018e-02, -4.5741e-03, -6.7860e-02],\n",
      "          [-8.0271e-02, -2.4705e-02,  4.6484e-02,  9.1726e-03, -4.8870e-02],\n",
      "          [-6.0609e-02,  1.3034e-02, -1.3010e-02,  8.1577e-02, -5.3801e-02]],\n",
      "\n",
      "         [[-6.5195e-02,  5.2124e-02, -1.0815e-02,  4.7701e-02,  3.6002e-02],\n",
      "          [-5.3096e-02,  4.2597e-02,  3.8779e-02, -6.0649e-02, -2.8590e-02],\n",
      "          [ 6.1916e-02, -3.2417e-02,  2.7939e-02,  6.6584e-02,  2.4469e-02],\n",
      "          [ 7.3681e-02, -1.6897e-02,  5.5165e-02, -7.0445e-02, -4.7293e-02],\n",
      "          [-5.4955e-02,  1.3221e-02, -4.0720e-02,  3.7494e-02,  1.9747e-02]],\n",
      "\n",
      "         [[-4.5312e-02,  3.5176e-02, -1.8231e-03,  6.4778e-02,  6.8129e-02],\n",
      "          [ 4.6777e-02, -3.9487e-02,  3.2030e-02,  6.1040e-02, -3.9729e-02],\n",
      "          [-1.4192e-03,  5.7135e-02, -3.4219e-03,  6.7837e-02, -7.5242e-02],\n",
      "          [-4.5956e-03,  7.7147e-02,  4.8026e-02, -7.9307e-02,  6.4605e-02],\n",
      "          [ 6.5104e-02, -8.1139e-02,  1.7584e-02,  6.8766e-02, -3.4632e-03]],\n",
      "\n",
      "         [[-3.2986e-03, -5.0137e-02,  1.4906e-02, -5.5157e-02, -5.2595e-02],\n",
      "          [-2.5788e-02, -6.7731e-02, -4.2034e-03, -5.4311e-02, -1.2773e-02],\n",
      "          [-1.8766e-02, -6.4891e-02, -2.7653e-02, -7.6521e-02,  5.6048e-02],\n",
      "          [ 7.7303e-02, -5.9435e-02, -4.6992e-02,  4.1581e-02,  4.2326e-02],\n",
      "          [-2.9568e-03, -7.8505e-02,  4.6714e-03,  3.1457e-02,  6.7790e-02]],\n",
      "\n",
      "         [[ 6.5101e-02,  4.7236e-02, -1.6405e-02,  7.3842e-02,  7.5358e-02],\n",
      "          [-9.9722e-03, -3.7539e-02,  1.9725e-02,  2.9727e-02,  5.6453e-03],\n",
      "          [ 3.3770e-02,  4.0642e-02, -6.9312e-02, -7.0036e-02, -3.9961e-02],\n",
      "          [ 2.2734e-02, -2.8104e-02, -6.6690e-02, -7.6654e-02,  3.6463e-02],\n",
      "          [-4.4807e-02, -3.9692e-02,  3.4101e-02, -7.9825e-02, -2.5165e-02]],\n",
      "\n",
      "         [[-4.1122e-02,  6.4411e-02,  2.5080e-02,  5.1922e-02, -6.7533e-02],\n",
      "          [-7.8535e-02,  2.3451e-02,  6.2734e-02, -7.6220e-02,  1.2271e-03],\n",
      "          [ 1.7985e-02,  6.3392e-02, -3.3649e-02,  1.4595e-02, -1.1373e-03],\n",
      "          [ 5.8186e-03,  1.5526e-02,  3.1741e-02, -6.4135e-02, -2.1425e-02],\n",
      "          [-7.2004e-02,  5.1337e-02,  7.6902e-02, -2.1274e-02, -2.7772e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.1225e-02,  3.7592e-02,  6.1583e-02, -7.6054e-02,  7.7052e-02],\n",
      "          [-4.0651e-02, -4.2441e-02,  1.2971e-02, -7.3511e-02, -2.8356e-02],\n",
      "          [-2.4278e-02,  5.4511e-02,  1.0338e-02, -4.0387e-02, -3.7571e-02],\n",
      "          [-5.5870e-02,  2.6615e-03,  3.0329e-02, -6.2635e-03,  1.3264e-02],\n",
      "          [ 5.0718e-02,  6.0170e-02, -1.7893e-02, -2.8320e-03,  6.3071e-02]],\n",
      "\n",
      "         [[-2.4336e-02, -7.0270e-02,  3.9792e-02, -1.4215e-02, -4.2448e-02],\n",
      "          [ 9.0818e-03,  6.5040e-02, -3.4224e-02,  6.0722e-02,  3.7544e-02],\n",
      "          [-5.1054e-02,  3.7980e-02, -2.9660e-02, -6.6805e-02,  5.5303e-02],\n",
      "          [-5.1978e-02,  7.1160e-02, -3.4536e-02,  6.5386e-02, -6.7790e-02],\n",
      "          [ 3.5336e-02, -4.6648e-02,  3.4432e-02, -1.1251e-02,  2.9700e-02]],\n",
      "\n",
      "         [[ 7.5540e-02, -4.6157e-02, -6.7197e-02,  5.4740e-02, -4.1652e-02],\n",
      "          [ 6.3759e-02,  7.7073e-02,  4.2986e-02,  4.2678e-02,  8.4051e-03],\n",
      "          [ 6.4153e-02, -1.5882e-02, -6.3525e-02, -5.3213e-02, -6.2854e-02],\n",
      "          [ 4.6717e-02, -4.0300e-02, -5.3112e-02, -7.5838e-02,  2.5185e-02],\n",
      "          [ 3.5597e-02, -1.2944e-02,  2.6569e-02,  5.7880e-02,  1.7439e-02]],\n",
      "\n",
      "         [[ 9.8841e-03, -5.1212e-02, -1.2919e-02,  9.5845e-03,  2.1430e-02],\n",
      "          [ 6.0786e-02, -2.8375e-02,  2.8552e-02, -3.5915e-02,  5.6448e-03],\n",
      "          [-7.7197e-02,  7.3764e-02, -1.9617e-02, -7.2261e-02,  7.2940e-02],\n",
      "          [-5.7402e-02, -1.2957e-02, -7.2460e-02, -3.9031e-02,  4.3705e-02],\n",
      "          [ 1.8115e-02,  6.0491e-02, -6.5506e-02,  6.6831e-02, -2.9053e-02]],\n",
      "\n",
      "         [[ 6.3679e-02,  1.0990e-02, -4.5176e-02, -5.7519e-02, -2.4913e-02],\n",
      "          [ 3.1235e-03,  3.4707e-02,  3.1906e-02,  3.5313e-02,  1.7966e-02],\n",
      "          [-4.8119e-02, -8.1261e-02,  2.8973e-02,  7.5292e-02, -7.6111e-02],\n",
      "          [ 3.0228e-02,  7.7081e-02,  8.0314e-02,  4.4665e-02,  7.2441e-02],\n",
      "          [-8.1594e-02, -1.3055e-02, -6.4857e-02,  6.9143e-02,  6.7893e-02]],\n",
      "\n",
      "         [[-2.7312e-02,  6.4267e-02, -3.7469e-02, -3.5823e-02,  3.2802e-02],\n",
      "          [ 8.7706e-03,  2.4349e-02,  2.5115e-02, -6.7384e-02, -1.3293e-02],\n",
      "          [ 6.3747e-02, -4.1296e-03, -7.0028e-02, -7.3661e-02, -6.4975e-03],\n",
      "          [ 3.2964e-02, -3.7907e-02, -3.1794e-02,  6.1829e-02,  3.5944e-02],\n",
      "          [ 4.7346e-03, -7.4150e-02,  6.1578e-02, -3.8806e-02,  6.4773e-03]]],\n",
      "\n",
      "\n",
      "        [[[-7.3826e-02,  2.0912e-02,  2.0314e-02,  4.1930e-02, -4.5308e-02],\n",
      "          [-5.0825e-02, -1.8956e-02,  3.3328e-02,  2.5216e-04,  6.2955e-02],\n",
      "          [ 1.3809e-02,  1.3511e-03,  6.4141e-04,  7.0759e-02,  2.9554e-02],\n",
      "          [-2.0804e-03, -6.7675e-02,  4.5764e-02,  7.5576e-02,  6.9475e-02],\n",
      "          [ 7.9044e-02,  2.6381e-02, -3.5508e-02, -2.8350e-02, -8.3956e-03]],\n",
      "\n",
      "         [[-6.5327e-02,  7.0949e-02, -3.8020e-02,  6.6954e-02, -2.1777e-02],\n",
      "          [-6.5354e-03, -6.0485e-02, -4.0805e-02,  3.2890e-02,  3.8500e-02],\n",
      "          [-2.7859e-02,  3.5471e-02, -3.6979e-03, -4.9482e-02, -2.5464e-02],\n",
      "          [-6.6736e-02,  4.3451e-02,  2.8081e-02, -6.6289e-02, -5.2315e-02],\n",
      "          [-2.7121e-02,  7.6680e-02,  8.3053e-03, -2.8923e-02, -7.4142e-02]],\n",
      "\n",
      "         [[ 4.3891e-02,  8.0609e-02, -6.5650e-02,  5.4517e-03,  1.1670e-02],\n",
      "          [-7.8387e-03,  2.0559e-02, -4.8443e-02,  2.3261e-02, -2.3924e-02],\n",
      "          [-5.1055e-02, -8.8227e-03,  6.7091e-02,  7.6886e-02,  7.4190e-02],\n",
      "          [ 7.5264e-02,  6.8244e-02, -7.9933e-02, -3.3363e-02,  7.2719e-02],\n",
      "          [-2.2582e-02, -4.2576e-02, -3.1408e-02,  4.6433e-03, -6.1555e-02]],\n",
      "\n",
      "         [[ 2.0555e-02,  7.2650e-02, -5.0084e-02,  5.4449e-02, -5.9985e-02],\n",
      "          [-6.9834e-02,  1.4601e-02,  6.7020e-02,  4.6241e-02,  6.1388e-04],\n",
      "          [ 2.1201e-02,  3.8842e-02, -1.0058e-02,  7.9263e-02,  1.4575e-03],\n",
      "          [-2.2138e-02, -4.7604e-02,  9.2929e-03,  4.6465e-02,  5.5442e-02],\n",
      "          [-3.5760e-02,  6.2875e-02,  2.0131e-02, -1.8222e-04, -1.3774e-02]],\n",
      "\n",
      "         [[-3.7678e-02, -6.3368e-03, -2.5932e-02,  1.8883e-02, -5.0548e-02],\n",
      "          [ 3.2708e-02, -7.8826e-02, -1.6826e-02,  1.7892e-02,  7.9301e-02],\n",
      "          [-4.5498e-02, -2.0060e-02,  4.1698e-02, -7.8196e-02,  4.9643e-02],\n",
      "          [-1.5930e-03, -6.2212e-03,  2.5984e-02,  1.2192e-02,  4.3412e-02],\n",
      "          [-6.7952e-02,  5.8716e-03, -1.7373e-04,  1.0476e-02, -7.6310e-02]],\n",
      "\n",
      "         [[ 2.6120e-02, -7.0300e-02, -7.0933e-02, -3.7725e-02, -4.0426e-02],\n",
      "          [-5.5204e-02, -8.5202e-03, -4.6878e-02,  5.8843e-02,  8.0396e-02],\n",
      "          [-6.9152e-02,  2.6902e-02,  4.7048e-02,  6.7027e-02, -7.5980e-02],\n",
      "          [-6.1838e-02,  5.6694e-02,  6.2879e-03, -6.5011e-02,  4.2056e-03],\n",
      "          [ 3.8132e-02,  8.1103e-02, -9.5532e-03,  2.6574e-02,  3.3293e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5964e-02,  2.6405e-02, -6.4200e-02, -4.6903e-02,  2.8367e-02],\n",
      "          [ 8.0256e-02, -3.6464e-02, -5.8698e-02,  7.9658e-02,  4.6857e-02],\n",
      "          [ 8.9408e-03, -5.3439e-02,  5.6804e-02, -6.2601e-02,  1.7411e-02],\n",
      "          [-4.4484e-02, -4.0353e-02,  2.0351e-02,  6.0318e-02, -5.5044e-02],\n",
      "          [-7.9950e-03,  5.3501e-02,  2.3261e-02, -1.8018e-02,  3.0191e-02]],\n",
      "\n",
      "         [[ 1.9445e-03,  1.9780e-02, -2.9693e-02, -5.9167e-02,  6.0053e-02],\n",
      "          [ 7.3330e-02, -7.7566e-02,  7.7326e-02, -2.4285e-02, -1.8038e-02],\n",
      "          [-4.3034e-02,  2.0916e-02,  5.0462e-02,  9.8723e-03, -3.0358e-02],\n",
      "          [-3.8984e-02, -7.9725e-02, -8.8815e-03,  2.1418e-02, -4.1392e-02],\n",
      "          [ 6.9258e-02, -6.7373e-02, -9.9851e-03,  7.2369e-02, -6.2224e-02]],\n",
      "\n",
      "         [[-4.7828e-02, -3.5644e-02, -5.6939e-02, -5.1953e-02,  3.0983e-02],\n",
      "          [ 6.9826e-02, -5.3775e-02, -3.7467e-02,  5.7943e-02, -1.3948e-02],\n",
      "          [-6.7311e-02,  6.3353e-02,  4.4580e-02, -1.9739e-02, -1.2038e-02],\n",
      "          [-5.9795e-02, -6.1447e-03,  7.1856e-02,  7.2095e-02, -6.1616e-02],\n",
      "          [-1.0711e-02,  4.7824e-02, -1.9022e-02, -5.1268e-02, -4.3001e-02]],\n",
      "\n",
      "         [[-1.0702e-02, -6.8342e-02,  6.4173e-02,  2.7003e-02, -2.6346e-02],\n",
      "          [ 7.8328e-02,  6.3328e-02,  4.9486e-02,  3.9392e-02, -6.2175e-02],\n",
      "          [ 4.1768e-02,  5.8801e-02,  1.1942e-03, -1.6956e-02, -1.7089e-02],\n",
      "          [ 6.5919e-02,  3.5118e-02, -6.0424e-02, -3.4797e-02, -9.1240e-03],\n",
      "          [ 2.8724e-02, -7.4664e-02, -6.0206e-02,  1.8498e-02, -2.5234e-02]],\n",
      "\n",
      "         [[ 1.9919e-02,  6.3177e-02,  6.0138e-02,  1.1977e-02,  5.8920e-02],\n",
      "          [-6.9529e-02, -7.7439e-02, -3.8466e-02, -2.1637e-02, -7.1805e-02],\n",
      "          [ 1.5526e-02, -5.3575e-03,  8.1157e-02, -7.2189e-02,  2.7723e-02],\n",
      "          [-3.1885e-02,  5.2540e-02,  7.3387e-02, -1.6042e-02, -6.9590e-02],\n",
      "          [ 3.2272e-02,  2.5134e-02, -6.8930e-02,  7.1237e-02, -6.3726e-02]],\n",
      "\n",
      "         [[-9.4120e-03, -1.3688e-02,  8.1460e-02,  1.6793e-02,  3.7410e-02],\n",
      "          [-2.9796e-02, -5.6664e-02, -1.6669e-03,  1.7779e-02,  3.3874e-02],\n",
      "          [-6.9803e-02,  1.3077e-02, -4.3779e-02, -1.9449e-02, -5.7199e-02],\n",
      "          [-4.1390e-02,  6.8184e-02, -1.8335e-02,  1.4195e-02,  7.2842e-03],\n",
      "          [ 3.8655e-03, -5.1635e-02,  4.6152e-02, -4.4585e-02,  1.0414e-02]]]]))\n",
      "('conv2.bias', tensor([ 0.0693, -0.0399, -0.0131, -0.0621,  0.0352,  0.0802, -0.0252, -0.0573,\n",
      "         0.0036,  0.0398, -0.0216,  0.0737,  0.0187,  0.0280,  0.0797, -0.0518])) ('conv2.bias', tensor([ 0.0611, -0.0350,  0.0301, -0.0195, -0.0284, -0.0714,  0.0331,  0.0235,\n",
      "        -0.0205, -0.0452,  0.0673,  0.0069,  0.0405,  0.0181,  0.0712, -0.0749]))\n",
      "('fc1.weight', tensor([[ 0.0310,  0.0137,  0.0024,  ...,  0.0112, -0.0294, -0.0432],\n",
      "        [-0.0050,  0.0442, -0.0254,  ..., -0.0423,  0.0022, -0.0113],\n",
      "        [-0.0161, -0.0429, -0.0491,  ...,  0.0405, -0.0442,  0.0367],\n",
      "        ...,\n",
      "        [-0.0378, -0.0295,  0.0330,  ..., -0.0087, -0.0217,  0.0384],\n",
      "        [-0.0164, -0.0117,  0.0481,  ...,  0.0043,  0.0428, -0.0266],\n",
      "        [-0.0168, -0.0340,  0.0043,  ...,  0.0482,  0.0388,  0.0382]])) ('fc1.weight', tensor([[ 0.0197, -0.0013,  0.0302,  ...,  0.0126, -0.0223,  0.0436],\n",
      "        [ 0.0328, -0.0485, -0.0378,  ..., -0.0456, -0.0368, -0.0203],\n",
      "        [-0.0230, -0.0237, -0.0352,  ..., -0.0429, -0.0411, -0.0496],\n",
      "        ...,\n",
      "        [ 0.0241,  0.0247, -0.0052,  ..., -0.0405,  0.0244, -0.0091],\n",
      "        [-0.0101, -0.0102, -0.0326,  ...,  0.0381,  0.0117, -0.0150],\n",
      "        [ 0.0016,  0.0315, -0.0318,  ..., -0.0425, -0.0458,  0.0206]]))\n",
      "('fc1.bias', tensor([ 4.7053e-02,  6.4391e-03,  1.0813e-03,  1.8386e-02,  1.0521e-02,\n",
      "        -4.9653e-02,  3.0367e-03, -4.3845e-02, -1.0698e-02,  4.2218e-02,\n",
      "        -8.4264e-03, -3.8779e-03, -2.3233e-02, -1.8182e-02, -1.1980e-02,\n",
      "        -4.9861e-02,  1.1601e-02, -5.4695e-03, -5.0542e-03, -4.5372e-02,\n",
      "        -3.8646e-02,  2.9927e-02, -1.2543e-02, -5.0364e-03,  8.0673e-03,\n",
      "         4.4255e-02,  3.3067e-02, -3.9847e-02, -2.2738e-02, -1.8769e-02,\n",
      "        -4.4433e-02, -2.5862e-02,  1.6686e-02, -2.0730e-02, -1.4715e-04,\n",
      "         3.8994e-02,  9.5623e-03,  3.4585e-02, -3.1051e-02, -3.5410e-02,\n",
      "         8.2055e-03,  1.9311e-02, -2.6972e-03, -4.3813e-02, -3.8691e-02,\n",
      "        -2.6627e-02,  1.3192e-02,  4.6736e-02,  4.2157e-02,  3.1251e-02,\n",
      "        -2.1233e-02, -7.3536e-03, -2.9630e-02, -4.3831e-03, -9.5233e-03,\n",
      "        -3.4651e-02,  1.8440e-02,  4.9283e-04,  2.7353e-02,  2.6578e-02,\n",
      "         3.6653e-02, -3.1878e-02,  2.9712e-02,  3.5069e-02, -2.6144e-02,\n",
      "        -1.3334e-03,  3.7975e-02, -4.7906e-02,  2.2487e-02, -2.4594e-03,\n",
      "         4.1690e-02, -3.5834e-02, -3.3570e-02,  1.6639e-02, -1.4830e-03,\n",
      "         4.6859e-02,  4.6572e-02, -4.9147e-02,  3.5310e-02, -4.7697e-02,\n",
      "         3.8646e-02, -1.6562e-03,  1.0081e-05,  4.1106e-02, -7.4137e-03,\n",
      "        -8.4958e-04,  1.1321e-02, -6.7126e-03, -9.0089e-03, -4.4487e-02,\n",
      "        -1.7074e-02,  1.3234e-02,  4.7730e-02,  3.2077e-02,  1.0769e-02,\n",
      "        -2.5610e-03,  3.6811e-02, -3.4837e-02,  2.3903e-02, -4.1879e-02,\n",
      "         1.9713e-02, -2.4083e-02,  1.3773e-02,  2.7551e-02, -4.9969e-02,\n",
      "        -1.4591e-02, -9.4434e-03,  2.1395e-02,  3.0436e-02, -2.7040e-03,\n",
      "        -1.0808e-02, -1.2760e-02, -7.6436e-03,  2.1542e-02, -4.0365e-02,\n",
      "         2.3381e-02,  4.0269e-02,  1.1862e-02,  2.4090e-02,  4.6209e-02])) ('fc1.bias', tensor([ 0.0367, -0.0145,  0.0234,  0.0177,  0.0120, -0.0273,  0.0045,  0.0323,\n",
      "         0.0222, -0.0211, -0.0255, -0.0334,  0.0395,  0.0009,  0.0306,  0.0023,\n",
      "        -0.0148,  0.0147,  0.0193, -0.0133,  0.0180, -0.0098,  0.0366, -0.0316,\n",
      "         0.0289,  0.0153,  0.0488,  0.0308, -0.0089, -0.0068, -0.0440, -0.0011,\n",
      "        -0.0488, -0.0414,  0.0178,  0.0373, -0.0040,  0.0121,  0.0406,  0.0094,\n",
      "        -0.0011, -0.0051,  0.0314, -0.0063,  0.0374,  0.0268, -0.0238,  0.0449,\n",
      "        -0.0341, -0.0246, -0.0357,  0.0255, -0.0401, -0.0295, -0.0432,  0.0156,\n",
      "         0.0384, -0.0357,  0.0265, -0.0437, -0.0093,  0.0445,  0.0496,  0.0216,\n",
      "        -0.0165,  0.0406,  0.0023, -0.0209,  0.0275,  0.0225, -0.0368, -0.0238,\n",
      "         0.0164,  0.0071, -0.0150, -0.0211, -0.0212,  0.0234, -0.0189,  0.0134,\n",
      "        -0.0405, -0.0303,  0.0276,  0.0290, -0.0249, -0.0348, -0.0183, -0.0382,\n",
      "         0.0316,  0.0261,  0.0076,  0.0441,  0.0137,  0.0029, -0.0117,  0.0078,\n",
      "        -0.0217, -0.0042,  0.0462,  0.0373,  0.0208,  0.0166,  0.0003, -0.0359,\n",
      "         0.0426,  0.0311, -0.0232,  0.0204,  0.0241,  0.0320, -0.0307,  0.0030,\n",
      "        -0.0377,  0.0132,  0.0115, -0.0368, -0.0334,  0.0471, -0.0480, -0.0382]))\n",
      "('fc2.weight', tensor([[-0.0392, -0.0891,  0.0413,  ..., -0.0591,  0.0697,  0.0265],\n",
      "        [-0.0052, -0.0162, -0.0351,  ..., -0.0899, -0.0401, -0.0548],\n",
      "        [ 0.0772, -0.0288,  0.0790,  ...,  0.0725, -0.0447,  0.0506],\n",
      "        ...,\n",
      "        [-0.0266,  0.0021,  0.0130,  ..., -0.0443,  0.0665,  0.0095],\n",
      "        [-0.0472, -0.0068,  0.0429,  ...,  0.0121, -0.0903,  0.0509],\n",
      "        [ 0.0576, -0.0064,  0.0006,  ..., -0.0283,  0.0778,  0.0007]])) ('fc2.weight', tensor([[ 0.0324,  0.0387, -0.0514,  ...,  0.0398, -0.0042,  0.0148],\n",
      "        [ 0.0045, -0.0668,  0.0577,  ..., -0.0084,  0.0517,  0.0181],\n",
      "        [-0.0875, -0.0547,  0.0581,  ...,  0.0232, -0.0169, -0.0418],\n",
      "        ...,\n",
      "        [ 0.0241, -0.0119,  0.0662,  ...,  0.0535, -0.0214,  0.0415],\n",
      "        [-0.0375, -0.0809, -0.0359,  ..., -0.0098, -0.0209,  0.0801],\n",
      "        [ 0.0845,  0.0892, -0.0503,  ..., -0.0294,  0.0155, -0.0770]]))\n",
      "('fc2.bias', tensor([ 0.0704,  0.0438, -0.0257,  0.0088, -0.0846,  0.0135, -0.0786,  0.0628,\n",
      "         0.0190,  0.0516,  0.0552,  0.0814, -0.0455, -0.0367, -0.0838,  0.0772,\n",
      "         0.0360,  0.0766,  0.0129, -0.0578, -0.0150, -0.0168,  0.0772,  0.0821,\n",
      "         0.0666,  0.0502, -0.0401, -0.0259, -0.0351, -0.0082,  0.0036, -0.0386,\n",
      "         0.0233, -0.0834, -0.0840, -0.0889, -0.0297, -0.0896, -0.0600, -0.0602,\n",
      "         0.0074, -0.0136, -0.0785,  0.0775,  0.0023, -0.0136, -0.0851, -0.0428,\n",
      "         0.0651,  0.0585,  0.0721,  0.0417, -0.0298,  0.0770,  0.0668,  0.0659,\n",
      "         0.0290, -0.0088, -0.0546, -0.0815, -0.0258, -0.0508,  0.0384, -0.0159,\n",
      "         0.0776, -0.0203,  0.0152,  0.0125,  0.0582, -0.0909,  0.0290, -0.0370,\n",
      "        -0.0094,  0.0340, -0.0526, -0.0759,  0.0726, -0.0906, -0.0143,  0.0337,\n",
      "         0.0383,  0.0207,  0.0227,  0.0443])) ('fc2.bias', tensor([ 0.0307,  0.0482, -0.0529,  0.0895, -0.0583,  0.0717,  0.0814,  0.0362,\n",
      "        -0.0301, -0.0007, -0.0072,  0.0616,  0.0452, -0.0692, -0.0708, -0.0229,\n",
      "        -0.0129,  0.0437, -0.0668, -0.0300,  0.0251, -0.0228, -0.0040, -0.0854,\n",
      "         0.0893, -0.0258, -0.0347, -0.0421,  0.0365,  0.0037,  0.0443, -0.0086,\n",
      "        -0.0015, -0.0455,  0.0116, -0.0748,  0.0263, -0.0171, -0.0800, -0.0075,\n",
      "         0.0471, -0.0726,  0.0253,  0.0472, -0.0776,  0.0738, -0.0822,  0.0415,\n",
      "        -0.0756, -0.0868,  0.0732,  0.0020, -0.0820,  0.0476, -0.0777,  0.0740,\n",
      "         0.0529,  0.0906, -0.0522,  0.0083,  0.0233, -0.0036,  0.0063, -0.0054,\n",
      "         0.0353, -0.0743, -0.0789, -0.0080, -0.0562,  0.0069,  0.0775, -0.0701,\n",
      "        -0.0441, -0.0696,  0.0669,  0.0912,  0.0306, -0.0790, -0.0590, -0.0360,\n",
      "         0.0571, -0.0621, -0.0789, -0.0193]))\n",
      "('fc3.weight', tensor([[-1.0841e-01,  4.3750e-02,  6.9604e-02,  5.8203e-02, -1.4106e-02,\n",
      "         -6.7920e-03,  6.6468e-02, -8.8493e-02, -3.1659e-02,  5.5119e-03,\n",
      "         -9.6815e-02, -2.4587e-02,  8.2815e-02, -6.2790e-02, -4.2028e-02,\n",
      "         -3.8309e-02, -4.0303e-02,  2.9993e-02, -9.1128e-02, -4.2543e-02,\n",
      "         -8.8409e-02, -6.8152e-02,  8.2330e-02,  2.1285e-02,  6.7801e-02,\n",
      "         -1.5939e-02, -4.5048e-02,  5.4341e-02,  8.4258e-02,  4.7532e-02,\n",
      "          9.3757e-02, -8.9372e-02,  7.4074e-02,  2.5917e-02, -8.5330e-02,\n",
      "          5.8292e-02,  1.9231e-02, -8.5722e-02, -4.8557e-02, -3.4697e-02,\n",
      "          9.3271e-02,  8.3732e-02,  2.7342e-02,  9.9224e-02,  7.0954e-02,\n",
      "         -9.5179e-02, -6.0016e-02,  9.5360e-02, -9.5384e-02,  6.6391e-02,\n",
      "         -8.4946e-02, -6.7172e-02,  6.0578e-02,  7.7958e-02,  4.1223e-02,\n",
      "          4.2638e-03,  1.0279e-03,  6.9086e-02, -7.4660e-02,  5.5444e-02,\n",
      "         -2.6290e-02,  4.4631e-02, -4.1956e-02,  1.0866e-01,  6.9490e-02,\n",
      "         -6.7146e-02, -1.2094e-02,  5.7981e-02,  1.7110e-02, -2.3884e-02,\n",
      "         -5.8393e-02,  4.6538e-03,  2.4177e-02,  8.3810e-02, -7.6403e-02,\n",
      "         -9.1909e-02, -4.8651e-02,  1.4277e-02, -3.5545e-02,  6.9384e-02,\n",
      "         -3.3966e-02,  6.7037e-02,  4.1562e-02, -3.8457e-02],\n",
      "        [ 7.9142e-02, -1.0559e-01, -2.8573e-02, -5.1818e-02, -5.8263e-02,\n",
      "         -6.5097e-02,  5.8448e-02,  4.8827e-02,  1.4828e-02,  6.2443e-02,\n",
      "         -3.3154e-03,  8.0803e-02,  1.6858e-02, -6.4088e-02,  8.0548e-02,\n",
      "         -1.5920e-02, -6.8416e-02, -4.5822e-02,  2.6589e-02, -4.4402e-02,\n",
      "          1.5990e-02,  8.5268e-02,  1.4975e-02, -8.3157e-02,  4.2316e-02,\n",
      "         -5.4229e-02,  7.8132e-02,  6.7487e-02, -9.8241e-02, -1.0357e-01,\n",
      "         -7.2863e-02, -3.7702e-03,  5.8929e-02, -1.0675e-01,  5.0139e-03,\n",
      "         -6.0754e-03, -4.6326e-02,  1.7779e-02,  4.8700e-02, -3.0505e-03,\n",
      "          6.4727e-02, -2.0122e-03,  2.8026e-02,  3.1118e-02, -8.1738e-02,\n",
      "         -5.8903e-02,  4.9826e-02, -3.1040e-02,  1.9923e-02, -5.2642e-02,\n",
      "         -8.4772e-03, -2.3921e-02, -8.3069e-02,  1.9303e-02,  5.6320e-02,\n",
      "         -4.7079e-02, -2.8489e-02, -1.8494e-02, -4.1805e-02, -2.9111e-02,\n",
      "         -2.7122e-02,  7.2370e-02,  7.9838e-02,  7.1778e-02, -4.5844e-02,\n",
      "         -9.6082e-03,  3.9258e-02, -7.6083e-02, -8.7387e-02,  8.6155e-03,\n",
      "          7.3513e-02, -3.9730e-03,  6.2297e-02,  1.0349e-01, -4.1607e-02,\n",
      "         -7.9797e-02, -2.0579e-05, -4.3584e-02,  1.3080e-02, -5.4095e-02,\n",
      "         -4.1291e-02, -5.3531e-02,  7.7006e-03,  5.2512e-02],\n",
      "        [ 3.5406e-03, -8.7451e-02, -1.9686e-03,  6.5341e-02,  6.7700e-02,\n",
      "          6.0615e-02,  2.0226e-02,  1.0725e-01, -1.0098e-01,  5.3826e-02,\n",
      "         -4.2266e-02, -2.8243e-02,  1.7786e-02,  7.0896e-02,  4.5107e-02,\n",
      "          4.9586e-02,  3.1580e-02, -2.0515e-02,  8.7322e-02, -1.5687e-02,\n",
      "         -4.3881e-02,  1.0264e-02,  3.1676e-02,  8.3086e-02, -2.3644e-02,\n",
      "         -9.2012e-02,  1.0142e-01,  7.5784e-03, -1.0337e-01, -5.8320e-02,\n",
      "          9.8645e-02, -1.2359e-04,  7.2048e-02, -6.5806e-02,  2.1971e-02,\n",
      "          1.0608e-02,  6.3817e-02, -9.5007e-02,  8.0085e-02,  3.4810e-03,\n",
      "         -7.4613e-02, -6.7267e-02, -2.4496e-02,  7.1822e-02, -5.3557e-02,\n",
      "          9.5598e-02, -9.6479e-02,  7.1566e-02,  9.6545e-04, -9.2162e-02,\n",
      "          1.0279e-01,  4.6373e-02, -6.0407e-02,  6.3400e-02,  1.0398e-01,\n",
      "         -3.8786e-02, -6.7863e-02,  9.5134e-02, -1.4820e-03, -8.6455e-02,\n",
      "         -2.8232e-02, -4.5397e-02, -9.9138e-02,  2.3433e-02, -9.2424e-03,\n",
      "          7.7015e-02,  1.0907e-01,  6.8383e-02,  3.3147e-02,  1.0456e-02,\n",
      "         -3.3693e-02,  2.4475e-02,  4.3269e-02,  3.7683e-02, -1.0201e-01,\n",
      "         -7.9612e-02,  1.0325e-01,  1.0169e-01,  4.1833e-02, -1.0716e-01,\n",
      "          9.7467e-02, -5.2648e-02, -5.0088e-02, -5.4264e-02],\n",
      "        [-5.5043e-02,  4.2458e-02, -2.9031e-02,  1.9202e-03,  5.9822e-02,\n",
      "          1.0739e-01, -3.8153e-02,  8.3913e-02,  5.9284e-02,  1.9360e-02,\n",
      "         -6.0294e-02, -8.5329e-02, -9.1395e-02, -9.8708e-02, -3.9462e-02,\n",
      "         -4.7891e-02, -9.3064e-02,  9.6334e-02,  3.1932e-02, -1.0837e-01,\n",
      "          1.0330e-01,  6.9640e-02,  8.2133e-02,  9.0481e-02,  3.6403e-02,\n",
      "          9.1053e-02, -1.0274e-01,  4.6363e-02,  2.4939e-02, -1.0545e-01,\n",
      "          6.4151e-02,  6.0951e-02,  7.8512e-02,  2.8838e-02,  8.7285e-02,\n",
      "          7.7748e-02,  4.2579e-02,  5.3750e-03, -4.3490e-02,  6.9887e-04,\n",
      "         -6.7117e-02,  5.5007e-02,  1.4628e-02, -4.1422e-02, -1.0359e-02,\n",
      "         -2.0111e-02, -3.4972e-03,  1.7040e-02,  6.2893e-02,  5.9960e-03,\n",
      "         -5.9793e-02,  1.0101e-02, -9.5183e-02,  2.1336e-02, -6.2553e-03,\n",
      "          8.7429e-02,  1.0649e-01, -2.8347e-02, -1.0857e-01, -1.9884e-02,\n",
      "          8.6557e-02, -6.9283e-02,  9.6890e-02, -3.5021e-02,  1.6175e-02,\n",
      "         -6.8322e-02, -2.5818e-02,  9.8845e-02, -1.0286e-01, -3.4207e-03,\n",
      "          1.0289e-01, -5.8694e-02, -1.1415e-02,  4.7763e-02, -8.8473e-02,\n",
      "          7.0947e-02,  1.4198e-02, -5.4788e-03,  2.1654e-02,  1.8463e-04,\n",
      "         -1.6352e-02, -3.5107e-02,  8.5099e-03,  2.8196e-02],\n",
      "        [-1.4956e-02, -4.6885e-02, -1.0419e-01,  4.7866e-03,  2.1746e-02,\n",
      "         -7.6279e-02,  3.1119e-03, -6.6822e-03,  4.7501e-02, -2.3625e-03,\n",
      "         -8.7493e-02,  9.9676e-02,  2.1683e-02, -5.7888e-02,  9.4492e-02,\n",
      "         -2.3110e-02,  6.7768e-02, -6.1248e-02, -7.4557e-02, -5.9339e-02,\n",
      "          6.6879e-03, -9.6214e-02,  9.5500e-02, -5.6075e-02,  7.7359e-02,\n",
      "          3.6089e-02,  1.1599e-02, -3.6789e-02, -1.0937e-02, -4.9626e-02,\n",
      "         -7.6177e-03, -9.9906e-02,  6.8092e-03,  8.9681e-02, -7.9967e-02,\n",
      "          4.7594e-02,  8.3316e-02,  7.2227e-02, -1.0905e-02,  1.0699e-01,\n",
      "          5.6664e-02,  1.4292e-02,  2.6341e-02, -8.2674e-02,  3.8011e-02,\n",
      "          6.2450e-02, -5.3892e-02, -7.2464e-02,  9.0279e-02,  3.5943e-02,\n",
      "          5.4948e-02, -5.4177e-02,  5.8149e-02,  8.3858e-02, -8.1105e-02,\n",
      "         -6.0596e-02,  1.0048e-01,  1.0662e-01,  4.0724e-02,  5.0706e-02,\n",
      "         -1.0423e-01, -6.9405e-03, -3.4154e-02,  2.6888e-02,  1.9183e-02,\n",
      "         -8.9141e-02,  5.2647e-02, -1.5494e-02, -2.5306e-02,  7.7230e-02,\n",
      "         -2.0165e-02,  3.6483e-02,  5.7605e-02, -6.4665e-02,  1.0572e-01,\n",
      "          8.5736e-02,  4.4207e-02, -7.5208e-02,  2.4574e-02, -2.1043e-02,\n",
      "          8.2616e-02, -7.4979e-02,  9.2513e-03, -7.4154e-02],\n",
      "        [ 9.0577e-02, -1.0203e-01,  1.0476e-01,  3.1445e-02,  1.0189e-01,\n",
      "         -8.0486e-02, -5.1941e-02,  9.5552e-02,  6.7180e-02, -9.1024e-02,\n",
      "          8.5374e-02,  4.0935e-02,  5.5633e-02, -8.3445e-02,  4.8384e-03,\n",
      "          8.9090e-02, -4.4550e-02, -5.0692e-02, -3.6365e-02,  5.8147e-02,\n",
      "         -7.6363e-02, -8.9341e-03,  9.5106e-02,  8.1904e-02, -4.1576e-02,\n",
      "         -3.3187e-02,  9.6590e-02,  1.8573e-02,  1.0247e-01,  4.1284e-02,\n",
      "          3.4436e-02,  3.0080e-02,  8.3304e-02,  6.0722e-03,  1.0484e-01,\n",
      "          8.7002e-02, -7.9768e-02,  4.0616e-02,  9.9863e-02,  6.1621e-02,\n",
      "         -8.3336e-02, -3.3036e-02,  8.2952e-02, -6.9314e-02,  8.5247e-02,\n",
      "          1.0103e-01,  2.4761e-02,  3.1754e-02, -2.7664e-04, -5.6181e-02,\n",
      "          6.6245e-02,  3.5714e-02, -8.6658e-02, -1.0299e-01,  8.4377e-02,\n",
      "         -6.5577e-02, -5.9586e-02,  8.7261e-02, -3.9537e-02, -1.0164e-01,\n",
      "          4.2992e-02, -8.1419e-02,  2.3787e-02, -1.1292e-02, -1.0427e-01,\n",
      "          1.7724e-02, -7.2435e-02, -4.6489e-02,  1.0723e-01, -1.0908e-01,\n",
      "         -2.2786e-02,  5.2315e-02, -7.8917e-02, -8.3624e-02,  5.3704e-02,\n",
      "          7.1288e-02,  3.4836e-03,  8.2353e-02, -8.5726e-02,  2.8758e-02,\n",
      "          7.5122e-02,  7.5545e-02,  7.1920e-03,  5.3396e-02],\n",
      "        [-7.3271e-02,  1.5503e-03,  7.2006e-02,  1.0602e-02, -7.4849e-02,\n",
      "         -1.1941e-02, -8.2141e-02, -7.8853e-02, -1.5272e-02, -7.2181e-02,\n",
      "         -7.4475e-02, -4.7341e-02, -3.1231e-02, -1.9597e-03, -3.8132e-02,\n",
      "          3.4853e-02,  1.7387e-02, -2.3954e-02,  3.3179e-02,  9.3807e-02,\n",
      "          7.9299e-02,  4.8026e-02, -4.9741e-02,  3.5047e-02, -4.4630e-02,\n",
      "          7.4091e-02,  8.4925e-03, -3.5327e-02,  9.4907e-02,  1.9307e-02,\n",
      "          4.6477e-02,  2.4506e-02, -3.1784e-02, -7.5617e-02,  6.7321e-02,\n",
      "          9.8005e-02,  9.8320e-03, -6.0173e-02, -1.0728e-01,  7.9283e-02,\n",
      "         -1.0430e-02,  2.0386e-02, -3.2413e-02, -3.0657e-02, -7.0223e-02,\n",
      "         -5.2092e-02, -1.3655e-02, -1.7658e-02,  2.0744e-02, -3.3186e-02,\n",
      "          9.2532e-02, -4.1578e-02,  3.7520e-02,  5.0840e-02,  2.0221e-02,\n",
      "         -1.4757e-02, -4.4224e-02,  8.0127e-02, -6.6945e-02,  4.5559e-02,\n",
      "         -4.1230e-02, -4.8583e-02,  7.2870e-03, -4.1154e-02, -6.6683e-02,\n",
      "          6.3852e-02,  1.3474e-02,  6.4372e-02,  2.5797e-02, -8.5498e-02,\n",
      "          8.0117e-03,  5.7895e-02, -9.3629e-02, -7.0167e-03,  1.0593e-01,\n",
      "          6.9298e-02, -7.4450e-02, -3.0633e-02,  4.1873e-02,  8.7957e-03,\n",
      "         -8.2812e-02,  1.1830e-02, -9.6028e-02,  3.8617e-02],\n",
      "        [ 4.9044e-02,  3.2024e-02, -7.6208e-02, -9.7538e-02,  1.0544e-01,\n",
      "          4.5294e-02,  9.4167e-03, -6.4376e-02, -2.9527e-02, -8.2901e-03,\n",
      "         -4.7408e-02, -5.5748e-04,  8.6234e-03, -1.1834e-02,  9.2363e-02,\n",
      "         -7.3050e-02, -1.9777e-02, -5.1573e-02, -8.0259e-02, -8.4900e-02,\n",
      "          2.6162e-02,  8.0237e-02, -1.0352e-01,  4.5102e-02, -1.3080e-02,\n",
      "         -7.0555e-02,  2.1260e-02, -3.5224e-02, -9.7933e-02, -9.6794e-02,\n",
      "         -5.6658e-02,  8.4702e-02,  3.7019e-02,  3.9611e-02, -7.8293e-02,\n",
      "         -3.8799e-02, -7.4124e-02,  1.0452e-01, -9.8765e-02, -1.8090e-02,\n",
      "          1.7559e-02, -6.9399e-02, -4.9275e-02, -7.3607e-02, -7.0780e-02,\n",
      "          8.5222e-02,  7.4963e-02,  1.0569e-01, -8.1526e-02, -1.0204e-02,\n",
      "          6.6780e-02,  7.2366e-02, -7.5920e-02, -2.7174e-02,  8.9306e-02,\n",
      "         -6.3207e-03, -8.5165e-02,  1.7694e-02,  8.5866e-02, -8.1101e-03,\n",
      "         -5.8989e-02,  1.3742e-02, -9.9277e-02, -5.1615e-03,  2.0172e-02,\n",
      "         -5.2149e-02, -2.8525e-02, -1.8352e-02,  3.8884e-02, -7.4104e-02,\n",
      "          1.0504e-01,  1.0187e-01, -1.0110e-01,  8.4944e-02, -2.7390e-02,\n",
      "         -4.9121e-02,  9.0141e-02,  7.2887e-02,  9.7579e-02,  1.0557e-01,\n",
      "          2.4757e-02,  1.0404e-01, -6.9639e-02,  6.2830e-03],\n",
      "        [-6.3737e-02,  3.2325e-02, -3.2134e-02, -4.9742e-03,  1.8554e-02,\n",
      "          5.3731e-02,  5.9960e-02,  5.7033e-02, -3.0369e-02, -1.0304e-01,\n",
      "         -4.2284e-02, -7.1747e-02,  8.4165e-03,  9.2124e-02,  5.5370e-02,\n",
      "         -3.6005e-02, -2.1080e-02, -3.7011e-02, -7.2982e-03,  6.8204e-02,\n",
      "          3.1162e-02, -5.6147e-02,  2.0621e-02, -3.9806e-02, -7.9834e-02,\n",
      "         -2.0135e-03,  5.4874e-02,  1.0356e-01,  2.9342e-02,  7.7549e-02,\n",
      "          4.5272e-02,  1.2331e-02, -1.7867e-02, -6.7419e-02,  7.1783e-02,\n",
      "         -1.0747e-01,  1.6093e-02, -3.9086e-02, -1.0175e-01, -1.0149e-01,\n",
      "         -3.3409e-02,  5.0176e-02,  5.2998e-03,  4.9285e-02, -5.5522e-02,\n",
      "          8.2281e-02, -1.4881e-02,  4.4338e-02, -9.0959e-02,  4.6707e-02,\n",
      "          3.4059e-02,  4.8151e-02,  3.5170e-02, -7.5685e-03, -3.7977e-02,\n",
      "          4.3015e-02, -3.9844e-02,  4.1966e-02,  2.3634e-02, -9.1093e-02,\n",
      "          9.7664e-02, -9.7419e-02, -3.4465e-02,  9.6281e-02, -2.7995e-02,\n",
      "         -7.7538e-02, -4.6496e-02, -4.3080e-02,  9.7007e-02,  2.4314e-02,\n",
      "          5.8756e-02, -6.2667e-02, -7.1598e-02, -7.1791e-02,  1.0806e-02,\n",
      "         -3.2002e-02, -2.6382e-02, -8.6781e-02, -7.0783e-02,  1.8583e-02,\n",
      "         -5.2997e-02,  3.3658e-02, -5.3316e-03,  6.0552e-02],\n",
      "        [-3.2102e-02,  1.0092e-01, -1.3609e-02,  4.7159e-02, -1.0272e-01,\n",
      "          2.5731e-02, -1.1060e-02,  7.4986e-02,  1.0169e-01,  7.1472e-02,\n",
      "         -1.0828e-01, -1.0870e-01,  8.8815e-02, -4.8594e-02,  5.6135e-04,\n",
      "          1.0158e-01, -6.0061e-02,  1.0429e-01, -1.0634e-02, -8.2866e-02,\n",
      "          3.7822e-02,  4.3702e-02,  5.0125e-03, -5.7709e-02,  3.7073e-02,\n",
      "         -7.0449e-02, -1.0711e-01,  4.3292e-02,  4.9272e-02, -4.5420e-02,\n",
      "          1.6073e-02, -9.9510e-02,  2.3129e-02,  2.4397e-02, -6.6593e-02,\n",
      "          4.9952e-02, -1.0175e-01, -6.0377e-02, -1.6882e-02,  6.5797e-02,\n",
      "          8.4561e-02,  3.4116e-02,  7.1671e-02,  7.4930e-02,  8.0293e-02,\n",
      "          4.1974e-02, -6.1680e-02,  8.2711e-02,  4.7492e-02,  9.7564e-02,\n",
      "         -6.8258e-02, -1.8162e-02, -4.4475e-02,  1.2080e-02,  9.5370e-03,\n",
      "         -9.2127e-02,  6.1590e-02, -7.8372e-02, -6.3356e-03, -5.5976e-02,\n",
      "          3.9706e-02, -6.3481e-02,  1.0702e-01, -6.8439e-02,  4.4086e-02,\n",
      "         -9.1572e-02,  3.3007e-02, -6.2514e-02, -4.6535e-02, -8.6859e-02,\n",
      "         -3.6750e-02, -5.8963e-02,  1.2526e-02, -1.6992e-02,  4.3763e-02,\n",
      "         -6.3555e-02, -2.1306e-02, -1.3324e-02,  5.8206e-03, -2.7259e-04,\n",
      "         -4.5204e-02,  1.0743e-01,  6.6534e-02, -3.0433e-02]])) ('fc3.weight', tensor([[-9.6694e-02,  4.8625e-02, -8.2451e-02,  1.0787e-01, -8.2417e-02,\n",
      "         -8.7464e-02, -3.2157e-02, -6.6915e-02, -7.4372e-02, -7.6715e-02,\n",
      "          9.9368e-03, -1.3829e-02,  8.0510e-02, -2.6810e-02,  5.2976e-02,\n",
      "         -6.7579e-02, -1.5855e-03,  4.7534e-02,  5.4383e-02, -2.9238e-03,\n",
      "          2.2750e-02,  6.8571e-02,  9.4518e-04,  7.8577e-02,  1.9253e-02,\n",
      "         -1.0695e-01,  1.8982e-02, -3.9502e-02,  3.6893e-02,  1.2183e-02,\n",
      "         -8.9376e-02,  5.5190e-02, -9.1411e-02, -2.0132e-02,  6.3152e-02,\n",
      "          2.5654e-02, -4.5156e-02, -1.0091e-01,  1.2850e-02,  3.1713e-02,\n",
      "         -9.6499e-02,  6.4368e-02,  8.5478e-02, -3.4752e-02, -3.5594e-02,\n",
      "          3.4816e-02,  6.7361e-02,  1.9479e-02,  2.3943e-02,  3.1693e-02,\n",
      "         -2.1244e-02,  1.0130e-01,  7.4556e-02, -9.1294e-02, -8.9210e-02,\n",
      "         -4.4006e-02,  1.0721e-01, -4.4078e-02,  4.5672e-02, -8.7251e-02,\n",
      "          5.9914e-02, -5.5888e-02,  1.0729e-01,  2.6799e-02,  3.9058e-02,\n",
      "          1.0565e-01,  1.6979e-02, -9.9668e-02,  5.3465e-02,  7.6957e-02,\n",
      "          8.6377e-02, -1.7218e-02, -7.0701e-02, -5.5261e-03, -5.1477e-02,\n",
      "          1.9673e-02, -5.3300e-02,  4.0096e-02, -9.4557e-02, -1.1093e-02,\n",
      "         -3.9712e-02, -9.0538e-02, -4.5028e-03,  8.2494e-02],\n",
      "        [ 3.0591e-02,  3.2892e-02,  5.5822e-02,  4.5027e-02,  2.4279e-02,\n",
      "          9.4928e-02, -9.6061e-03, -4.3537e-02, -1.0299e-01,  1.3417e-02,\n",
      "          7.9105e-02, -4.7220e-02,  9.0957e-02,  7.4473e-02, -4.9867e-03,\n",
      "         -5.2366e-02,  6.8210e-02, -8.9543e-02, -4.0945e-02, -4.7903e-02,\n",
      "          1.5874e-02,  1.9506e-02, -5.7157e-02,  5.3166e-02,  2.5690e-02,\n",
      "          5.9685e-02,  3.2982e-02, -8.8257e-03,  3.9766e-02, -2.5530e-02,\n",
      "          9.4692e-02,  9.4963e-02, -5.8818e-02, -5.2386e-03, -7.3866e-02,\n",
      "         -9.3400e-03, -3.0187e-02,  3.4670e-02, -7.2049e-02, -3.6571e-02,\n",
      "          3.5530e-02,  1.0897e-02, -3.3240e-02, -8.3768e-02, -5.5838e-02,\n",
      "         -4.9382e-02,  1.0876e-01, -4.3417e-02, -1.6116e-02,  1.0020e-01,\n",
      "         -8.7017e-02, -9.7258e-02, -7.0677e-02,  2.7636e-02, -3.0783e-03,\n",
      "         -9.9723e-02, -6.9954e-02,  4.3286e-02, -1.5108e-02,  6.2098e-02,\n",
      "          1.0712e-01, -7.6209e-02, -5.5381e-03,  2.1996e-02, -5.3366e-02,\n",
      "         -5.7348e-02, -1.0298e-01, -8.8694e-02,  1.0245e-01,  5.5601e-02,\n",
      "          5.5568e-02, -9.7333e-02, -4.6876e-02, -1.5742e-02,  5.3411e-02,\n",
      "         -8.7497e-02, -2.6854e-02, -1.0677e-02,  9.8097e-02, -6.2434e-02,\n",
      "         -2.6801e-02,  9.2490e-02,  8.5089e-02, -1.0016e-01],\n",
      "        [-9.1466e-02, -8.8011e-03, -5.5153e-02, -8.3461e-02,  6.0961e-02,\n",
      "          3.0100e-02, -9.9406e-02, -7.7666e-02, -6.0942e-02,  1.6253e-02,\n",
      "         -2.3387e-02, -9.5139e-02, -9.9412e-02,  8.1688e-02,  9.8838e-02,\n",
      "         -3.2433e-02, -3.9403e-02, -7.8572e-02, -2.5940e-02, -6.1137e-02,\n",
      "         -4.5937e-02, -9.8820e-02,  8.1709e-02, -8.6994e-02, -1.0732e-01,\n",
      "          5.3241e-02, -8.2845e-03,  3.5928e-02, -1.0735e-02, -1.8474e-02,\n",
      "          1.2645e-02,  5.2322e-02,  1.2351e-02, -6.3504e-02, -7.9211e-02,\n",
      "          3.3049e-02,  7.8432e-02,  4.3643e-02,  3.6432e-02,  9.4109e-03,\n",
      "         -3.9753e-02, -9.3354e-02, -1.0020e-01, -7.9063e-02, -6.3921e-02,\n",
      "         -8.9407e-02,  1.0677e-01,  2.7544e-02, -5.3064e-02, -1.0002e-01,\n",
      "         -4.1112e-02,  5.2965e-02, -8.6247e-02,  4.5899e-02, -7.6583e-02,\n",
      "         -5.5138e-02,  9.5356e-02, -1.6050e-02,  5.2425e-02, -8.2377e-02,\n",
      "         -1.0107e-01, -7.9006e-02, -2.8060e-02,  3.0537e-02,  5.3899e-02,\n",
      "          8.3594e-02,  1.7339e-02,  4.3829e-02,  5.4718e-02, -1.0845e-01,\n",
      "          1.7339e-02,  7.2907e-02, -2.0887e-02, -4.6538e-02,  7.8046e-02,\n",
      "          6.8881e-02,  8.8283e-02, -4.1960e-02,  9.7638e-02, -1.0084e-01,\n",
      "          1.0037e-01,  5.9478e-02,  4.8401e-02,  1.0013e-01],\n",
      "        [-2.0163e-02, -2.6518e-03,  3.1510e-02,  2.1177e-02,  4.3085e-02,\n",
      "          1.0032e-01,  4.7169e-02, -1.1756e-02,  1.0576e-01,  1.9395e-02,\n",
      "         -1.1013e-02,  8.0161e-02, -8.8843e-02, -1.1865e-03, -2.5944e-02,\n",
      "          7.7639e-02, -4.9101e-02, -7.5239e-02,  6.0535e-03,  7.2350e-02,\n",
      "         -7.4385e-02, -9.7229e-02,  8.9179e-02,  3.1370e-02, -6.9321e-02,\n",
      "         -3.6153e-02,  9.4329e-02, -5.0471e-02, -9.6935e-02, -1.2793e-03,\n",
      "          8.4331e-02, -5.2209e-02,  5.3585e-02, -5.5866e-02, -4.4933e-02,\n",
      "         -9.5623e-03,  8.6617e-02, -5.4507e-02, -4.5227e-02,  2.6941e-02,\n",
      "          5.5290e-02, -9.5931e-02, -6.4592e-02, -1.0061e-01,  2.2319e-02,\n",
      "         -8.3474e-02, -5.8890e-02,  7.7999e-02,  1.2239e-02,  7.1417e-02,\n",
      "         -1.6704e-02, -5.7213e-02, -2.1949e-03,  3.4417e-02,  5.4835e-02,\n",
      "          8.1834e-02, -4.3956e-02, -5.9814e-02, -9.5309e-02, -2.7842e-02,\n",
      "         -9.2565e-02,  6.9862e-02, -2.2812e-02, -2.6997e-02,  9.7235e-02,\n",
      "         -2.7160e-02, -9.9026e-02,  5.8824e-02, -3.2189e-03,  3.5381e-02,\n",
      "         -8.9267e-02,  8.6373e-02,  1.0740e-01, -2.5683e-02, -1.0276e-01,\n",
      "          4.2532e-02,  6.1413e-02, -6.0149e-02,  1.0457e-01,  5.8491e-02,\n",
      "         -5.7250e-02,  4.1009e-02,  1.6669e-02, -1.2291e-02],\n",
      "        [ 8.7842e-02, -4.0859e-03,  1.0735e-01,  6.0723e-02, -9.4485e-03,\n",
      "          1.1638e-02, -8.5230e-02,  3.3593e-02,  7.2372e-02, -4.9134e-02,\n",
      "          1.0070e-01, -1.7112e-02, -3.7175e-02, -9.8798e-02, -9.6351e-02,\n",
      "         -1.4165e-02,  5.6406e-02,  9.5671e-02, -3.6124e-02, -1.3540e-02,\n",
      "         -3.6218e-02,  5.4938e-03,  9.9823e-02,  4.5401e-02,  7.2010e-02,\n",
      "         -5.7009e-02,  6.7420e-02, -1.2139e-02,  7.1621e-02, -1.2990e-02,\n",
      "          7.2990e-02, -2.7224e-05, -4.1834e-02, -3.2249e-03,  6.2832e-02,\n",
      "         -5.3014e-02,  8.4741e-03,  1.2004e-02,  1.9851e-02,  3.4887e-04,\n",
      "         -3.9864e-02,  5.4679e-02,  8.7661e-02, -1.0717e-01,  9.1137e-02,\n",
      "          7.2397e-02, -1.2323e-02, -3.5370e-02,  1.3280e-02, -9.0542e-02,\n",
      "         -1.0420e-02,  9.7151e-02, -7.5720e-02,  7.8909e-03,  1.5825e-02,\n",
      "         -2.3711e-02, -5.8502e-02,  1.7094e-02,  7.9564e-02,  4.9320e-03,\n",
      "         -4.6190e-03,  6.4432e-02, -3.7786e-02, -7.9898e-02, -2.1561e-02,\n",
      "          9.2544e-02, -6.1802e-02, -5.6915e-02, -5.4849e-02, -5.1127e-02,\n",
      "         -6.4791e-02,  5.5263e-02,  2.1614e-02,  4.4799e-02, -6.7916e-02,\n",
      "          3.9192e-02,  1.4951e-02,  3.7197e-02, -4.3230e-02, -1.8684e-02,\n",
      "         -3.8762e-02, -1.4928e-02, -1.4436e-02, -3.5067e-02],\n",
      "        [-8.6559e-02,  3.1222e-02, -1.0427e-01,  8.6203e-02,  1.0146e-01,\n",
      "         -7.5175e-02, -6.7742e-03, -6.7254e-03,  5.6013e-02, -8.9207e-02,\n",
      "          6.0653e-02, -7.5092e-02,  3.1649e-02, -1.5332e-02, -5.0743e-02,\n",
      "          1.0895e-02,  1.0615e-01,  4.9064e-03,  4.7711e-02, -6.0479e-02,\n",
      "         -6.2021e-02, -6.4647e-02,  8.4238e-02, -1.9226e-03,  3.2256e-02,\n",
      "          1.0527e-01, -4.4513e-02,  7.8729e-02,  3.5707e-03,  6.5853e-02,\n",
      "         -2.9402e-02, -8.1110e-02,  8.9532e-02, -8.5391e-05, -7.7977e-02,\n",
      "          8.1492e-02,  7.4658e-02,  8.1923e-02,  8.7680e-02,  2.4526e-02,\n",
      "          1.7969e-02, -1.9615e-03,  2.6320e-03,  6.4783e-03, -5.6583e-02,\n",
      "         -1.3484e-02,  6.7684e-02, -4.0281e-02, -7.7961e-02, -7.6806e-02,\n",
      "         -6.8596e-02,  6.9387e-02,  7.0914e-02,  2.3727e-03, -7.2142e-02,\n",
      "          6.7752e-02,  7.3691e-02,  8.5786e-02, -5.9483e-02, -3.2965e-02,\n",
      "         -8.9901e-02, -4.2613e-02, -3.5555e-02,  2.4983e-02,  1.9282e-02,\n",
      "          9.0873e-02,  9.2903e-02,  2.7865e-02,  2.3294e-02,  4.1916e-02,\n",
      "          5.7478e-02, -3.6996e-02,  8.0887e-02, -6.9301e-02,  1.0673e-02,\n",
      "          1.0780e-01,  7.1164e-02, -1.8668e-02, -2.9849e-02,  4.0315e-02,\n",
      "         -9.5865e-02, -9.5999e-02,  1.0359e-01, -9.8148e-02],\n",
      "        [-6.1084e-02, -3.3820e-02, -3.0094e-02,  5.8360e-02,  3.4770e-02,\n",
      "         -9.3832e-02,  1.5765e-02,  6.0466e-02, -7.0755e-02, -1.1430e-02,\n",
      "          1.5278e-02,  7.8868e-02, -4.0611e-02, -3.7665e-02,  1.4468e-03,\n",
      "          5.6686e-02,  1.0904e-01,  1.3262e-02,  7.7427e-02, -8.3593e-02,\n",
      "         -8.0218e-02,  1.6895e-02,  7.0325e-02, -1.0004e-01,  7.6318e-02,\n",
      "          7.2585e-03, -1.4927e-02, -8.1647e-02, -1.9770e-02,  6.4766e-02,\n",
      "          9.1337e-02,  5.5366e-02, -4.8352e-02,  1.3383e-02, -9.1832e-02,\n",
      "          3.4041e-02,  3.0642e-03,  1.8977e-02, -2.9376e-02, -5.1515e-02,\n",
      "         -1.9804e-02,  7.7881e-02, -5.9131e-02,  4.4680e-02, -5.7872e-02,\n",
      "         -3.1068e-02, -1.3611e-02, -8.6623e-02,  8.4486e-02, -9.7255e-02,\n",
      "          7.7768e-02,  7.0532e-02,  1.2781e-02,  8.6088e-02, -2.8236e-02,\n",
      "          6.1111e-02,  5.6014e-02, -5.4388e-02,  8.7557e-02, -7.0026e-02,\n",
      "         -6.4778e-02, -8.1366e-04, -2.0600e-02,  6.2460e-02, -4.2297e-02,\n",
      "          6.7527e-02, -1.9667e-02,  1.0565e-01, -7.1133e-02,  7.4546e-02,\n",
      "          9.3242e-03, -4.0332e-02, -9.7207e-03,  2.3662e-02,  8.6168e-02,\n",
      "         -9.0172e-02,  5.2768e-02,  1.3699e-02, -9.0369e-02, -8.1151e-02,\n",
      "         -7.1194e-02, -5.8290e-02,  4.8188e-02,  4.2829e-02],\n",
      "        [ 6.8487e-02,  2.1860e-02,  6.8850e-02,  7.7218e-02,  7.3770e-02,\n",
      "         -9.9671e-02, -4.2075e-02, -7.4359e-02, -6.7251e-02,  6.1551e-02,\n",
      "         -1.4858e-02, -6.9110e-02, -4.7747e-02, -7.4170e-02, -5.4032e-02,\n",
      "          2.5385e-02,  4.2045e-02,  5.1622e-02,  2.3598e-02,  8.8808e-02,\n",
      "          1.0554e-01, -5.4095e-02, -8.2693e-02,  1.1898e-02,  8.3035e-02,\n",
      "         -7.8987e-02, -1.9971e-02,  3.7047e-02,  6.0077e-02, -1.4961e-02,\n",
      "          6.4108e-03, -8.4378e-02, -5.3896e-02, -5.5764e-03, -1.0539e-02,\n",
      "         -6.5632e-02, -1.0251e-01,  3.0938e-02, -7.0543e-02, -5.2980e-02,\n",
      "         -5.4664e-02, -7.5884e-02, -6.3235e-02, -4.4920e-02,  1.0736e-01,\n",
      "          5.3831e-02,  7.2222e-02, -3.9180e-02,  1.5408e-02,  4.3059e-02,\n",
      "          2.5741e-02, -7.0783e-02,  3.6568e-02,  1.0185e-01,  1.2630e-02,\n",
      "         -8.4157e-02, -2.2327e-02, -7.9294e-02,  7.9580e-02,  1.0445e-01,\n",
      "         -6.7067e-02,  7.8228e-02, -3.2270e-02, -6.4928e-02, -1.2072e-02,\n",
      "          7.4058e-03,  5.8120e-02, -6.8718e-02,  5.1442e-04,  1.1092e-02,\n",
      "          9.1218e-02,  3.4063e-02,  5.6893e-02,  6.7253e-02, -4.3333e-02,\n",
      "          8.7577e-02,  1.4916e-02, -9.2070e-02, -9.1225e-02,  7.0248e-02,\n",
      "         -1.3295e-02,  7.5293e-03,  3.7138e-03, -2.7858e-02],\n",
      "        [-2.7296e-02, -3.8102e-02,  7.2499e-02,  3.6254e-02,  9.1069e-02,\n",
      "          5.0404e-03, -9.0759e-02,  4.7850e-02,  1.0400e-01, -4.5482e-02,\n",
      "          4.5021e-02,  2.6829e-02, -1.0086e-01, -2.5743e-04,  8.8103e-02,\n",
      "          7.9293e-02,  9.6322e-02, -3.8429e-02, -1.0385e-01, -3.4860e-02,\n",
      "         -2.3399e-02, -4.1334e-02,  3.7745e-02, -1.0711e-02,  8.1254e-02,\n",
      "          4.2296e-02, -5.0343e-02, -3.0714e-04, -1.0064e-02,  5.4063e-02,\n",
      "          7.7615e-03,  5.0119e-02,  4.3768e-02, -1.0456e-01,  2.7615e-02,\n",
      "         -1.0107e-01,  4.5428e-02,  7.7456e-02, -4.1205e-02, -6.1271e-02,\n",
      "          5.6565e-02,  1.5354e-02,  3.1595e-02,  1.0647e-01, -5.3071e-02,\n",
      "         -3.1306e-02, -1.8696e-02, -3.0340e-02,  4.5923e-02, -3.3711e-02,\n",
      "         -9.6157e-02,  9.3615e-02,  3.2314e-02, -6.5348e-04, -1.4186e-02,\n",
      "         -7.2579e-02, -2.5609e-02,  1.0143e-01, -3.2727e-02,  1.0766e-01,\n",
      "         -4.9489e-02, -4.6465e-02, -7.1645e-02, -6.4878e-02, -3.8312e-02,\n",
      "         -7.5114e-02,  2.7978e-02,  7.6088e-02, -1.1123e-02, -6.7986e-02,\n",
      "         -1.3616e-03, -3.8422e-02, -1.0597e-01, -5.0185e-02,  6.5519e-02,\n",
      "          1.7513e-03, -4.4242e-02,  4.5370e-02,  7.2101e-02,  9.9693e-02,\n",
      "          2.7754e-02, -4.9561e-02,  1.0541e-01,  2.4401e-02],\n",
      "        [ 4.1875e-03, -9.6759e-02,  9.6695e-02, -1.0230e-01,  8.4013e-02,\n",
      "         -1.0141e-03,  5.2694e-02,  9.4180e-02, -9.0775e-02, -1.0486e-01,\n",
      "         -7.8500e-02, -6.4169e-02,  1.4093e-02, -9.2428e-02, -8.6754e-02,\n",
      "         -4.4107e-02,  3.9733e-02, -6.4658e-02, -5.2277e-02,  3.1497e-02,\n",
      "         -1.1286e-02,  7.4773e-02, -3.9865e-02, -3.7614e-02, -3.7515e-02,\n",
      "         -9.0082e-02,  3.8139e-02, -8.9462e-04, -8.4036e-02,  5.4867e-02,\n",
      "          6.7712e-02, -6.1120e-02, -6.6686e-03, -6.9418e-02, -8.6623e-02,\n",
      "         -3.1380e-02, -5.7138e-02, -1.0354e-01, -7.0976e-02, -1.3798e-02,\n",
      "          3.6324e-02, -1.0404e-01, -9.0515e-02, -8.1756e-02, -7.9061e-02,\n",
      "         -2.2050e-02,  4.7849e-02, -3.9617e-02,  7.4984e-02, -8.6345e-03,\n",
      "          8.9295e-02, -9.5430e-02, -4.7531e-02,  7.7365e-02,  9.9297e-02,\n",
      "          8.4941e-03,  8.9769e-03, -7.5284e-02,  8.1936e-02,  9.2575e-02,\n",
      "         -2.7665e-02, -5.2121e-02,  5.0698e-02,  5.9487e-02,  6.9979e-02,\n",
      "         -1.0810e-01, -7.2246e-02, -4.3839e-02,  6.0800e-02, -8.3685e-02,\n",
      "          3.6830e-02,  3.8503e-02,  9.0315e-02,  2.3088e-02,  9.4166e-02,\n",
      "          4.0674e-02,  4.8875e-02, -7.3729e-03, -8.6032e-02,  6.1672e-02,\n",
      "          7.6009e-03, -5.4798e-03, -6.2310e-02,  4.9372e-02]]))\n",
      "('fc3.bias', tensor([-0.0858, -0.0860, -0.0988,  0.0004, -0.0790, -0.0739, -0.0639, -0.0555,\n",
      "         0.0967,  0.1018])) ('fc3.bias', tensor([-0.0043, -0.0533, -0.0429,  0.0436,  0.0999,  0.0079, -0.0372, -0.0575,\n",
      "         0.0468,  0.0482]))\n"
     ]
    }
   ],
   "source": [
    "compare_models_step(net, net1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define a Loss function and optimizer\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(predictions, targets, epsilon=1e-12):\n",
    "    \"\"\"\n",
    "    Computes cross entropy between targets (encoded as one-hot vectors)\n",
    "    and predictions. \n",
    "    Input: predictions (N, k) ndarray\n",
    "           targets (N, k) ndarray        \n",
    "    Returns: scalar\n",
    "    \"\"\"\n",
    "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "    N = predictions.shape[0]\n",
    "    ce = -np.sum(targets*np.log(predictions))/N\n",
    "    return ce\n",
    "\n",
    "# predictions = np.clip(predictions, (1e-12),1-(1e-12))\n",
    "# N = targets.shape[0]\n",
    "# -np.sum(targets*np.log(predictions))/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.001\n",
       "    momentum: 0.9\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train the network\n",
    "^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "This is when things start to get interesting.\n",
    "We simply have to loop over our data iterator, and feed the inputs to the\n",
    "network and optimize.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.210\n",
      "[1,  4000] loss: 1.879\n",
      "[1,  6000] loss: 1.707\n",
      "[1,  8000] loss: 1.590\n",
      "[1, 10000] loss: 1.543\n",
      "[1, 12000] loss: 1.480\n",
      "[2,  2000] loss: 1.421\n",
      "[2,  4000] loss: 1.372\n",
      "[2,  6000] loss: 1.365\n",
      "[2,  8000] loss: 1.335\n",
      "[2, 10000] loss: 1.330\n",
      "[2, 12000] loss: 1.302\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3999 % 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly save our trained model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `here <https://pytorch.org/docs/stable/notes/serialization.html>`_\n",
    "for more details on saving PyTorch models.\n",
    "\n",
    "5. Test the network on the test data\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "We have trained the network for 2 passes over the training dataset.\n",
    "But we need to check if the network has learnt anything at all.\n",
    "\n",
    "We will check this by predicting the class label that the neural network\n",
    "outputs, and checking it against the ground-truth. If the prediction is\n",
    "correct, we add the sample to the list of correct predictions.\n",
    "\n",
    "Okay, first step. Let us display an image from the test set to get familiar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:    cat  ship  ship plane\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load back in our saved model (note: saving and re-loading the model\n",
    "wasn't necessary here, we only did it to illustrate how to do so):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs are energies for the 10 classes.\n",
    "The higher the energy for a class, the more the network\n",
    "thinks that the image is of the particular class.\n",
    "So, let's get the index of the highest energy:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:    dog  ship  ship plane\n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results seem pretty good.\n",
    "\n",
    "Let us look at how the network performs on the whole dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 53 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks way better than chance, which is 10% accuracy (randomly picking\n",
    "a class out of 10 classes).\n",
    "Seems like the network learnt something.\n",
    "\n",
    "Hmmm, what are the classes that performed well, and the classes that did\n",
    "not perform well:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 61 %\n",
      "Accuracy of   car : 65 %\n",
      "Accuracy of  bird : 47 %\n",
      "Accuracy of   cat : 27 %\n",
      "Accuracy of  deer : 52 %\n",
      "Accuracy of   dog : 47 %\n",
      "Accuracy of  frog : 52 %\n",
      "Accuracy of horse : 56 %\n",
      "Accuracy of  ship : 76 %\n",
      "Accuracy of truck : 51 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so what next?\n",
    "\n",
    "How do we run these neural networks on the GPU?\n",
    "\n",
    "Training on GPU\n",
    "----------------\n",
    "Just like how you transfer a Tensor onto the GPU, you transfer the neural\n",
    "net onto the GPU.\n",
    "\n",
    "Let's first define our device as the first visible cuda device if we have\n",
    "CUDA available:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.305\n",
      "[1,  4000] loss: 2.306\n",
      "[1,  6000] loss: 2.305\n",
      "[1,  8000] loss: 2.305\n",
      "[1, 10000] loss: 2.305\n",
      "[1, 12000] loss: 2.306\n",
      "[2,  2000] loss: 2.305\n",
      "[2,  4000] loss: 2.306\n",
      "[2,  6000] loss: 2.305\n",
      "[2,  8000] loss: 2.306\n",
      "[2, 10000] loss: 2.305\n",
      "[2, 12000] loss: 2.305\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of this section assumes that ``device`` is a CUDA device.\n",
    "\n",
    "Then these methods will recursively go over all modules and convert their\n",
    "parameters and buffers to CUDA tensors:\n",
    "\n",
    ".. code:: python\n",
    "\n",
    "    net.to(device)\n",
    "\n",
    "\n",
    "Remember that you will have to send the inputs and targets at every step\n",
    "to the GPU too:\n",
    "\n",
    ".. code:: python\n",
    "\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "Why dont I notice MASSIVE speedup compared to CPU? Because your network\n",
    "is really small.\n",
    "\n",
    "**Exercise:** Try increasing the width of your network (argument 2 of\n",
    "the first ``nn.Conv2d``, and argument 1 of the second ``nn.Conv2d`` –\n",
    "they need to be the same number), see what kind of speedup you get.\n",
    "\n",
    "**Goals achieved**:\n",
    "\n",
    "- Understanding PyTorch's Tensor library and neural networks at a high level.\n",
    "- Train a small neural network to classify images\n",
    "\n",
    "Training on multiple GPUs\n",
    "-------------------------\n",
    "If you want to see even more MASSIVE speedup using all of your GPUs,\n",
    "please check out :doc:`data_parallel_tutorial`.\n",
    "\n",
    "Where do I go next?\n",
    "-------------------\n",
    "\n",
    "-  :doc:`Train neural nets to play video games </intermediate/reinforcement_q_learning>`\n",
    "-  `Train a state-of-the-art ResNet network on imagenet`_\n",
    "-  `Train a face generator using Generative Adversarial Networks`_\n",
    "-  `Train a word-level language model using Recurrent LSTM networks`_\n",
    "-  `More examples`_\n",
    "-  `More tutorials`_\n",
    "-  `Discuss PyTorch on the Forums`_\n",
    "-  `Chat with other users on Slack`_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
